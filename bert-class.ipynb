{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bf2d7d",
   "metadata": {},
   "source": [
    "# LM for QA Tidy_XOR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5847f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "from bert_utils import (\n",
    "    predict,\n",
    "    prepare_data,\n",
    "    tokenize_function,\n",
    "    train_mbert,\n",
    ")\n",
    "\n",
    "# Huggingface imports\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c187f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device for training\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "df_train = dataset[\"train\"].to_polars()\n",
    "df_val = dataset[\"validation\"].to_polars()\n",
    "\n",
    "# Arabic, Telegu and Korean\n",
    "df_ar_train = df_train.filter(pl.col(\"lang\") == \"ar\")\n",
    "df_ar_val = df_val.filter(pl.col(\"lang\") == \"ar\")\n",
    "df_te_train = df_train.filter(pl.col(\"lang\") == \"te\")\n",
    "df_te_val = df_val.filter(pl.col(\"lang\") == \"te\")\n",
    "df_ko_train = df_train.filter(pl.col(\"lang\") == \"ko\")\n",
    "df_ko_val = df_val.filter(pl.col(\"lang\") == \"ko\")\n",
    "\n",
    "# Make a dict\n",
    "data = {\n",
    "    \"arabic\": {\"train\": df_ar_train, \"val\": df_ar_val},\n",
    "    \"telegu\": {\"train\": df_te_train, \"val\": df_te_val},\n",
    "    \"korean\": {\"train\": df_ko_train, \"val\": df_ko_val},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50abbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Arabic distribution train\n",
    "print(f\"Arabic TRAINING set size: {len(df_ar_train)} with a total of {df_ar_train['answerable'].sum()} answerable questions.\")\n",
    "print(f\"This gives a distribution of {df_ar_train['answerable'].sum() / len(df_ar_train) * 100:.2f}% answerable questions.\")    \n",
    "# Check Arabic distribution val\n",
    "print(f\"Arabic VALIDATION set size: {len(df_ar_val)} with a total of {df_ar_val['answerable'].sum()} answerable questions.\")\n",
    "print(f\"This gives a distribution of {df_ar_val['answerable'].sum() / len(df_ar_val) * 100:.2f}% answerable questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Telegu distribution train\n",
    "print(f\"Telegu TRAINING set size: {len(df_te_train)} with a total of {df_te_train['answerable'].sum()} answerable questions.\")\n",
    "print(f\"This gives a distribution of {df_te_train['answerable'].sum() / len(df_te_train) * 100:.2f}% answerable questions.\")    \n",
    "# Check Telegu distribution val\n",
    "print(f\"Telegu VALIDATION set size: {len(df_te_val)} with a total of {df_te_val['answerable'].sum()} answerable questions.\")\n",
    "print(f\"This gives a distribution of {df_te_val['answerable'].sum() / len(df_te_val) * 100:.2f}% answerable questions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Korean distribution train\n",
    "print(f\"Korean TRAINING set size: {len(df_ko_train)} with a total of {df_ko_train['answerable'].sum()} answerable questions.\")\n",
    "print(f\"This gives a distribution of {df_ko_train['answerable'].sum() / len(df_ko_train) * 100:.2f}% answerable questions.\")    \n",
    "# Check Korean distribution val\n",
    "print(f\"Korean VALIDATION set size: {len(df_ko_val)} with a total of {df_ko_val['answerable'].sum()} answerable questions.\")\n",
    "print(f\"This gives a distribution of {df_ko_val['answerable'].sum() / len(df_ko_val) * 100:.2f}% answerable questions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd5c62f",
   "metadata": {},
   "source": [
    "## Finetune the multilingual BERT for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifiers = {}\n",
    "all_tokenizers = {} # they're all the same\n",
    "mbert_checkpoint = \"bert-base-multilingual-uncased\"\n",
    "for lang in [\"arabic\", \"telegu\", \"korean\"]:\n",
    "    print(f\"\\n--- Processing language: {lang} ---\")\n",
    "    trained = False\n",
    "    classifiers_dir = \"./mbert_classifiers\"\n",
    "    save_path = f\"{lang}_mbert_answerable_classifier\"\n",
    "    full_save_path = os.path.join(classifiers_dir, save_path)\n",
    "    # Check if model exists\n",
    "    if not os.path.exists(classifiers_dir):\n",
    "        print(f\"No classifiers folder found, creating {classifiers_dir}...\")\n",
    "        os.makedirs(classifiers_dir)\n",
    "    if os.path.exists(full_save_path):\n",
    "        print(f\"Found existing model for {lang}, loading...\")\n",
    "        all_classifiers[lang] = AutoModelForSequenceClassification.from_pretrained(full_save_path)\n",
    "        all_tokenizers[lang] = AutoTokenizer.from_pretrained(full_save_path) # all the same, we don't train tokenizer\n",
    "        trained = True\n",
    "        print(f\"Model for {lang} loaded.\")\n",
    "\n",
    "    # If model doesn't exist, train it\n",
    "    if not trained:\n",
    "        print(\"Model not found, training new mBERT model...\")\n",
    "        mbert_tokenizer = AutoTokenizer.from_pretrained(mbert_checkpoint)\n",
    "        all_tokenizers[lang] = mbert_tokenizer # all the same, we don't train tokenizer\n",
    "        mbert_classifier = AutoModelForSequenceClassification.from_pretrained(\n",
    "            mbert_checkpoint,\n",
    "            num_labels=2,\n",
    "        )\n",
    "        # Prepare datasets\n",
    "        train_dataset = prepare_data(data[lang][\"train\"])\n",
    "        val_dataset = prepare_data(data[lang][\"val\"])\n",
    "\n",
    "        # Tokenize datasets - fix the function call\n",
    "        tokenized_train = train_dataset.map(lambda examples: tokenize_function(examples, mbert_tokenizer), batched=True)\n",
    "        tokenized_val = val_dataset.map(lambda examples: tokenize_function(examples, mbert_tokenizer), batched=True)\n",
    "        # Train\n",
    "        classifier, tokenizer = train_mbert(\n",
    "            tokenized_train,\n",
    "            tokenized_val,\n",
    "            model_checkpoint = mbert_checkpoint,\n",
    "            device=device,\n",
    "        ) # type: ignore\n",
    "        print(\"Saving model...\")\n",
    "        classifier.save_pretrained(full_save_path) # type: ignore\n",
    "        tokenizer.save_pretrained(full_save_path) # type: ignore\n",
    "        print(f\"Model trained and saved to {full_save_path}.\")\n",
    "        # Store the trained model in notebook variable\n",
    "        all_classifiers[lang] = AutoModelForSequenceClassification.from_pretrained(full_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390ea2da",
   "metadata": {},
   "source": [
    "## Compare pre-trained vs fine-tuned results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47dbe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained model and tokenizer\n",
    "pt_mbert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    mbert_checkpoint,\n",
    "    num_labels=2,\n",
    ")\n",
    "\n",
    "# Test on a few examples BEFORE training\n",
    "print(\"=\" * 50)\n",
    "print(\"BEFORE FINE-TUNING (Random Classification Head)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get a few examples from your validation set\n",
    "for i in range(3):\n",
    "    example = df_ar_val.row(i, named=True)\n",
    "    \n",
    "    result = predict(example['question'], example['context'], pt_mbert, mbert_tokenizer)\n",
    "    \n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Question: {example['question'][:100]}...\")\n",
    "    print(f\"Ground Truth: {'Answerable' if example['answerable'] else 'Not Answerable'}\")\n",
    "    print(f\"Prediction: {'Answerable' if result['prediction'] == 1 else 'Not Answerable'}\")\n",
    "    print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "    print(f\"Probs: [Not Answerable: {result['prob_class_0']:.3f}, Answerable: {result['prob_class_1']:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AFTER training on the same examples\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"AFTER FINE-TUNING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in range(3):\n",
    "    example = df_ar_val.row(i, named=True)\n",
    "\n",
    "    result = predict(example['question'], example['context'], mbert_classifier, mbert_tokenizer)\n",
    "\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Question: {example['question'][:100]}...\")\n",
    "    print(f\"Ground Truth: {'Answerable' if example['answerable'] else 'Not Answerable'}\")\n",
    "    print(f\"Prediction: {'Answerable' if result['prediction'] == 1 else 'Not Answerable'}\")\n",
    "    print(f\"Confidence: {result['confidence']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
