{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bf2d7d",
   "metadata": {},
   "source": [
    "# LM for QA Tidy_XOR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5847f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from nlm.models import BiLSTMClassifierModel\n",
    "from nlm.train_utils import train_classifier as train\n",
    "\n",
    "from bert_utils import (\n",
    "    display_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "df_train = dataset[\"train\"].to_polars()\n",
    "df_val = dataset[\"validation\"].to_polars()\n",
    "\n",
    "df_ar_train = df_train.filter(pl.col(\"lang\") == \"ar\")\n",
    "df_ko_train = df_train.filter(pl.col(\"lang\") == \"ko\")\n",
    "df_te_train = df_train.filter(pl.col(\"lang\") == \"te\")\n",
    "df_arkote_train = df_train.filter(pl.col(\"lang\").is_in([\"ar\", \"ko\", \"te\"]))\n",
    "\n",
    "df_ar_val = df_val.filter(pl.col(\"lang\") == \"ar\")\n",
    "df_ko_val = df_val.filter(pl.col(\"lang\") == \"ko\")\n",
    "df_te_val = df_val.filter(pl.col(\"lang\") == \"te\")\n",
    "df_arkote_val = df_val.filter(pl.col(\"lang\").is_in([\"ar\", \"ko\", \"te\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mBERT tokenizer\n",
    "mbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "mbert_model = AutoModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "pretrained_embeddings = mbert_model.get_input_embeddings().weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c187f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device for training\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a87e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_generator(\n",
    "        train_dataset: list, train_labels: list, val_dataset: list,\n",
    "        val_labels: list, tokenizer, device, batch_size: int = 8\n",
    ") -> tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Generate DataLoader objects for training and validation datasets for use in PyTorch models.\n",
    "    \"\"\"\n",
    "    train_tokens = tokenizer(\n",
    "        train_dataset,\n",
    "        truncation=True,\n",
    "        max_length=65,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    train_labels = torch.tensor(train_labels).to(device)\n",
    "\n",
    "    val_tokens = tokenizer(\n",
    "        val_dataset,\n",
    "        truncation=True,\n",
    "        max_length=65,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    val_labels = torch.tensor(val_labels).to(device)\n",
    "\n",
    "    train_attention_mask = train_tokens['attention_mask']\n",
    "    train_input_lens = train_attention_mask.sum(dim=1)\n",
    "    train_dataset = TensorDataset(\n",
    "        train_tokens['input_ids'], train_input_lens, train_labels\n",
    "    )\n",
    "\n",
    "    val_attention_mask = val_tokens['attention_mask']\n",
    "    val_input_lens = val_attention_mask.sum(dim=1)\n",
    "    val_dataset = TensorDataset(\n",
    "        val_tokens['input_ids'], val_input_lens, val_labels\n",
    "    )\n",
    "\n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dl, val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de63e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_model_loader(\n",
    "        train_dataset: list, train_labels:list, val_dataset: list,\n",
    "        val_labels: list, device, model_cache_path: str, epochs: int,\n",
    "        n_classes:int = 2, model_lstm_dim: int = 100\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Load or train a NN Model for text classification.\n",
    "    \"\"\"\n",
    "    model = BiLSTMClassifierModel(\n",
    "        pretrained_embeddings=torch.FloatTensor(pretrained_embeddings).to(device),\n",
    "        n_classes=n_classes,\n",
    "        lstm_dim=model_lstm_dim,\n",
    "    ).to(device)\n",
    "\n",
    "    if os.path.exists(model_cache_path):\n",
    "        print(\"Loading cached model from\", model_cache_path)\n",
    "        model.load_state_dict(torch.load(model_cache_path))\n",
    "    else:\n",
    "        print(\"No cached model found. Training a new model.\")\n",
    "        train_dl, val_dl = dataloader_generator(train_dataset, train_labels, val_dataset, val_labels, mbert_tokenizer, device)\n",
    "        losses, best_acc = train(model, train_dl, val_dl, torch.optim.Adam(model.parameters(), lr=1e-3), n_epochs=epochs, device=device, save_path=model_cache_path)\n",
    "        print('Training complete. Best validation accuracy:', best_acc)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67227fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabic dataset\n",
    "#arabic_model_path = \"cached_data/bilstm_class_arabic\"\n",
    "#df_arabic_train_questions = df_ar_train[\"question\"].to_list()\n",
    "#df_arabic_train_answerable = [int(x) for x in df_ar_train[\"answerable\"].to_list()]\n",
    "#df_arabic_val_questions = df_ar_val[\"question\"].to_list()\n",
    "#df_arabic_val_answerable = [int(x) for x in df_ar_val[\"answerable\"].to_list()]\n",
    "\n",
    "#arabic_model = class_model_loader(df_arabic_train_questions, df_arabic_train_answerable, df_arabic_val_questions, df_arabic_val_answerable, device, arabic_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f732018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabic dataset with context\n",
    "arabic_model_path = \"cached_data/bilstm_class_arabic_w_context\"\n",
    "df_arabic_train_questions_context = zip(df_ar_train[\"question\"].to_list() , df_ar_train[\"context\"].to_list())\n",
    "df_arabic_train_questions_context = [\"[SEP]\".join([q, c]) for q, c in df_arabic_train_questions_context]\n",
    "df_arabic_train_answerable = [int(x) for x in df_ar_train[\"answerable\"].to_list()]\n",
    "df_arabic_val_questions_context = zip(df_ar_val[\"question\"].to_list() , df_ar_val[\"context\"].to_list())\n",
    "df_arabic_val_questions_context = [\"[SEP]\".join([q, c]) for q, c in df_arabic_val_questions_context]\n",
    "df_arabic_val_answerable = [int(x) for x in df_ar_val[\"answerable\"].to_list()]\n",
    "\n",
    "arabic_model_w_context = class_model_loader(df_arabic_train_questions_context, df_arabic_train_answerable, df_arabic_val_questions_context, df_arabic_val_answerable, device, arabic_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db222aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korean dataset\n",
    "#korean_model_path = \"cached_data/bilstm_class_korean\"\n",
    "#df_korean_train_questions = df_ko_train[\"question\"].to_list()\n",
    "#df_korean_train_answerable = [int(x) for x in df_ko_train[\"answerable\"].to_list()]\n",
    "#df_korean_val_questions = df_ko_val[\"question\"].to_list()\n",
    "#df_korean_val_answerable = [int(x) for x in df_ko_val[\"answerable\"].to_list()]\n",
    "\n",
    "#korean_model = class_model_loader(df_korean_train_questions, df_korean_train_answerable, df_korean_val_questions, df_korean_val_answerable, device, korean_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korean dataset with context\n",
    "korean_model_path = \"cached_data/bilstm_class_korean_w_context\"\n",
    "df_korean_train_questions_context = zip(df_ko_train[\"question\"].to_list() , df_ko_train[\"context\"].to_list())\n",
    "df_korean_train_questions_context = [\"[SEP]\".join([q, c]) for q, c in df_korean_train_questions_context]\n",
    "df_korean_train_answerable = [int(x) for x in df_ko_train[\"answerable\"].to_list()]\n",
    "df_korean_val_questions_context = zip(df_ko_val[\"question\"].to_list() , df_ko_val[\"context\"].to_list())\n",
    "df_korean_val_questions_context = [\"[SEP]\".join([q, c]) for q, c in df_korean_val_questions_context]\n",
    "df_korean_val_answerable = [int(x) for x in df_ko_val[\"answerable\"].to_list()]\n",
    "\n",
    "korean_model_w_context = class_model_loader(df_korean_train_questions_context, df_korean_train_answerable, df_korean_val_questions_context, df_korean_val_answerable, device, korean_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31aef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telughu dataset\n",
    "#telugu_model_path = \"cached_data/bilstm_class_telugu\"\n",
    "#df_telugu_train_questions = df_te_train[\"question\"].to_list()\n",
    "#df_telugu_train_answerable = [int(x) for x in df_te_train[\"answerable\"].to_list()]\n",
    "#df_telugu_val_questions = df_te_val[\"question\"].to_list()\n",
    "#df_telugu_val_answerable = [int(x) for x in df_te_val[\"answerable\"].to_list()]\n",
    "\n",
    "#telugu_model = class_model_loader(df_telugu_train_questions, df_telugu_train_answerable, df_telugu_val_questions, df_telugu_val_answerable, device, telugu_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab84e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telugu dataset with context\n",
    "telugu_model_path = \"cached_data/bilstm_class_telugu_w_context\"\n",
    "df_telugu_train_questions_context = zip(df_te_train[\"question\"].to_list() , df_te_train[\"context\"].to_list())\n",
    "df_telugu_train_questions_context = [\"[SEP]\".join([q, c]) for q, c in df_telugu_train_questions_context]\n",
    "df_telugu_train_answerable = [int(x) for x in df_te_train[\"answerable\"].to_list()]\n",
    "df_telugu_val_questions_context = zip(df_te_val[\"question\"].to_list() , df_te_val[\"context\"].to_list())\n",
    "df_telugu_val_questions_context = [\"[SEP]\".join([q, c]) for q, c in df_telugu_val_questions_context]\n",
    "df_telugu_val_answerable = [int(x) for x in df_te_val[\"answerable\"].to_list()]\n",
    "\n",
    "telugu_model_w_context = class_model_loader(df_telugu_train_questions_context, df_telugu_train_answerable, df_telugu_val_questions_context, df_telugu_val_answerable, device, telugu_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context dataset\n",
    "#context_model_path = \"cached_data/bilstm_class_context\"\n",
    "#df_arkote_train_context = df_arkote_train[\"context\"].to_list()\n",
    "#df_arkote_train_answerable = [int(x) for x in df_arkote_train[\"answerable\"].to_list()]\n",
    "#df_arkote_val_context = df_arkote_val[\"context\"].to_list()\n",
    "#df_arkote_val_answerable = [int(x) for x in df_arkote_val[\"answerable\"].to_list()]\n",
    "\n",
    "#context_model = class_model_loader(df_arkote_train_context, df_arkote_train_answerable, df_arkote_val_context, df_arkote_val_answerable, device, context_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870fcfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answerable(model: BiLSTMClassifierModel, texts: list[str], tokenizer, device) -> list[int]:\n",
    "    model.eval()\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=65,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    input_lens = attention_mask.sum(dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, input_lens)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1).cpu().tolist()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d01921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_results(\n",
    "#    predict_answerable(arabic_model, df_arabic_val_questions, mbert_tokenizer, device),\n",
    "#    df_arabic_val_answerable,\n",
    "#    [\"N\", \"P\"],\n",
    "#    title=\"Arabic BiLSTM Confusion Matrix\"\n",
    "#)\n",
    "display_results(\n",
    "    predict_answerable(arabic_model_w_context, df_arabic_val_questions_context, mbert_tokenizer, device),\n",
    "    df_arabic_val_answerable,\n",
    "    [\"N\", \"P\"],\n",
    "    title=\"Arabic BiLSTM with Context Confusion Matrix\"\n",
    ")\n",
    "#display_results(\n",
    "#    predict_answerable(korean_model, df_korean_val_questions, mbert_tokenizer, device),\n",
    "#    df_korean_val_answerable,\n",
    "#    [\"N\", \"P\"],\n",
    "#    title=\"Korean BiLSTM Confusion Matrix\"\n",
    "#)\n",
    "display_results(\n",
    "    predict_answerable(korean_model_w_context, df_korean_val_questions_context, mbert_tokenizer, device),\n",
    "    df_korean_val_answerable,\n",
    "    [\"N\", \"P\"],\n",
    "    title=\"Korean BiLSTM with Context Confusion Matrix\"\n",
    ")\n",
    "#display_results(\n",
    "#    predict_answerable(telugu_model, df_telugu_val_questions, mbert_tokenizer, device),\n",
    "#    df_telugu_val_answerable,\n",
    "#    [\"N\", \"P\"],\n",
    "#    title=\"Telugu BiLSTM Confusion Matrix\"\n",
    "#)\n",
    "display_results(\n",
    "    predict_answerable(telugu_model_w_context, df_telugu_val_questions_context, mbert_tokenizer, device),\n",
    "    df_telugu_val_answerable,\n",
    "    [\"N\", \"P\"],\n",
    "    title=\"Telugu BiLSTM with Context Confusion Matrix\"\n",
    ")\n",
    "#display_results(\n",
    "#    predict_answerable(context_model, df_arkote_val_context, mbert_tokenizer, device),\n",
    "#    df_arkote_val_answerable,\n",
    "#    [\"N\", \"P\"],\n",
    "#    title=\"Context BiLSTM Confusion Matrix\"\n",
    "#)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
