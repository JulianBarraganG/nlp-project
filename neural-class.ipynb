{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bf2d7d",
   "metadata": {},
   "source": [
    "# LM for QA Tidy_XOR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5847f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.const import ARB_CACHE, KOR_CACHE, TELU_CACHE\n",
    "from nlm.models import BiLSTMClassifierModel\n",
    "from nlm.train_utils import train_classifier as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "mbert_model = AutoModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "pretrained_embeddings = mbert_model.get_input_embeddings().weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c187f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a87e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_generator(dataset: list, labels: list, tokenizer, device, test_split: float = 0.2, batch_size: int = 8) -> tuple[DataLoader, DataLoader]:\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        dataset,\n",
    "        truncation=True,\n",
    "        max_length=65,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    labels = torch.tensor(labels).to(device)\n",
    "\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    input_lens = attention_mask.sum(dim=1)\n",
    "\n",
    "    # Split into train and validation sets\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        range(input_ids.size(0)), test_size=test_split, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = TensorDataset(\n",
    "        input_ids[train_idx], input_lens[train_idx], labels[train_idx]\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        input_ids[val_idx], input_lens[val_idx], labels[val_idx]\n",
    "    )\n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dl, val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de63e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_model_loader(dataset: list, labels:list, device, model_cache_path: str, epochs: int, n_classes:int = 2, model_lstm_dim: int = 100) -> tuple[BiLSTMClassifierModel, float, float]:\n",
    "    model = BiLSTMClassifierModel(\n",
    "        pretrained_embeddings=torch.FloatTensor(pretrained_embeddings).to(device),\n",
    "        n_classes=n_classes,\n",
    "        lstm_dim=model_lstm_dim,\n",
    "    ).to(device)\n",
    "\n",
    "    if os.path.exists(model_cache_path):\n",
    "        print(\"Loading cached model from\", model_cache_path)\n",
    "        model.load_state_dict(torch.load(model_cache_path))\n",
    "    else:\n",
    "        print(\"No cached model found. Training a new model.\")\n",
    "        train_dl, val_dl = dataloader_generator(dataset, labels, mbert_tokenizer, device)\n",
    "        losses, best_acc = train(model, train_dl, val_dl, torch.optim.Adam(model.parameters(), lr=1e-3), n_epochs=epochs, device=device, save_path=model_cache_path)\n",
    "        print('Training complete. Best validation accuracy:', best_acc)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67227fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabic dataset\n",
    "arabic_model_path = \"cached_data/bilstm_class_arabic\"\n",
    "df_ar = pl.read_parquet(ARB_CACHE)\n",
    "df_arabic = df_ar[\"question\"].to_list()\n",
    "df_arabic_answerable = [int(x) for x in df_ar[\"answerable\"].to_list()]\n",
    "\n",
    "arabic_model = class_model_loader(df_arabic, df_arabic_answerable, device, arabic_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f732018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabic dataset with context\n",
    "arabic_model_path = \"cached_data/bilstm_class_arabic_w_context\"\n",
    "df_ar = pl.read_parquet(ARB_CACHE)\n",
    "df_arabic = zip(df_ar[\"question\"].to_list() , df_ar[\"context\"].to_list())\n",
    "df_arabic = [\"[SEP]\".join([q, c]) for q, c in df_arabic]\n",
    "df_arabic_answerable = [int(x) for x in df_ar[\"answerable\"].to_list()]\n",
    "\n",
    "arabic_model_w_context = class_model_loader(df_arabic, df_arabic_answerable, device, arabic_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db222aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korean dataset\n",
    "korean_model_path = \"cached_data/bilstm_class_korean\"\n",
    "df_ko = pl.read_parquet(KOR_CACHE)\n",
    "df_korean = df_ko[\"question\"].to_list()\n",
    "df_korean_answerable = [int(x) for x in df_ko[\"answerable\"].to_list()]\n",
    "\n",
    "korean_model = class_model_loader(df_korean, df_korean_answerable, device, korean_model_path,  epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korean dataset with context\n",
    "korean_model_path = \"cached_data/bilstm_class_korean_w_context\"\n",
    "df_ko = pl.read_parquet(KOR_CACHE)\n",
    "df_korean = zip(df_ko[\"question\"].to_list() , df_ko[\"context\"].to_list())\n",
    "df_korean = [\"[SEP]\".join([q, c]) for q, c in df_korean]\n",
    "df_korean_answerable = [int(x) for x in df_ko[\"answerable\"].to_list()]\n",
    "\n",
    "korean_model_w_context = class_model_loader(df_korean, df_korean_answerable, device, korean_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31aef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telughu dataset\n",
    "telugu_model_path = \"cached_data/bilstm_class_telugu\"\n",
    "df_telu = pl.read_parquet(TELU_CACHE)\n",
    "df_telugu = df_telu[\"question\"].to_list()\n",
    "df_telugu_answerable = [int(x) for x in df_telu[\"answerable\"].to_list()]\n",
    "\n",
    "telugu_model = class_model_loader(df_telugu, df_telugu_answerable, device, telugu_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab84e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telugu dataset with context\n",
    "telugu_model_path = \"cached_data/bilstm_class_telugu_w_context\"\n",
    "df_telu = pl.read_parquet(TELU_CACHE)\n",
    "df_telugu = zip(df_telu[\"question\"].to_list() , df_telu[\"context\"].to_list())\n",
    "df_telugu = [\"[SEP]\".join([q, c]) for q, c in df_telugu]\n",
    "df_telugu_answerable = [int(x) for x in df_telu[\"answerable\"].to_list()]\n",
    "\n",
    "telugu_model_w_context = class_model_loader(df_telugu, df_telugu_answerable, device, telugu_model_path, epochs=10, n_classes=2, model_lstm_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context dataset\n",
    "df_arkote = pl.concat([\n",
    "    df_ar,\n",
    "    df_ko,\n",
    "    df_telu\n",
    "])\n",
    "df_arkote_answerable = [int(x) for x in df_arkote[\"answerable\"].to_list()]\n",
    "\n",
    "context_model_path = \"cached_data/bilstm_class_context\"\n",
    "df_context = df_arkote[\"context\"].to_list()\n",
    "context_model = class_model_loader(df_context, df_arkote_answerable, device, context_model_path, epochs=10, n_classes=2, model_lstm_dim=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870fcfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answerable(model: BiLSTMClassifierModel, texts: list[str], tokenizer, device) -> list[int]:\n",
    "    model.eval()\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=65,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    input_lens = attention_mask.sum(dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, input_lens)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1).cpu().tolist()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ea072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_performance(true: list, pred: list):\n",
    "    # Proportion of answerable predictions\n",
    "    print(f\"Answerable proportion: {true.count(1) / len(true):.2f}\")\n",
    "    print(f\"Predicted answerable proportion: {pred.count(1) / len(pred):.2f}\")\n",
    "\n",
    "    # Evaluate the rule-based classification\n",
    "    true_positives = sum(1 for t, p in zip(true, pred) if t == 1 and p == 1)\n",
    "    false_positives = sum(1 for t, p in zip(true, pred) if t == 0 and p == 1)\n",
    "    true_negatives = sum(1 for t, p in zip(true, pred) if t == 0 and p == 0)\n",
    "    false_negatives = sum(1 for t, p in zip(true, pred) if t == 1 and p == 0)\n",
    "    print(f\"True Positives: {true_positives} , False Positives: {false_positives}\")\n",
    "    print(f\"True Negatives: {true_negatives} , False Negatives: {false_negatives}\")\n",
    "\n",
    "    # Accuracy, Precision, Recall, F1 Score\n",
    "    accuracy = (true_positives + true_negatives) / len(true)\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score:.2f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    confusion_matrix = [[true_positives, false_negatives],\n",
    "                        [false_positives, true_negatives]]\n",
    "    plt.imshow(confusion_matrix)\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0, 1], ['P', 'N'])\n",
    "    plt.yticks([0, 1], ['P', 'N'])\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d01921",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Arabic model without context:\")\n",
    "show_performance(df_arabic_answerable, predict_answerable(arabic_model, df_arabic, mbert_tokenizer, device))\n",
    "print(\"Arabic model with context:\")\n",
    "show_performance(df_arabic_answerable, predict_answerable(arabic_model_w_context, df_arabic, mbert_tokenizer, device))\n",
    "print(\"Korean model without context:\")\n",
    "show_performance(df_korean_answerable, predict_answerable(korean_model, df_korean, mbert_tokenizer, device))\n",
    "print(\"Korean model with context:\")\n",
    "show_performance(df_korean_answerable, predict_answerable(korean_model_w_context, df_korean, mbert_tokenizer, device))\n",
    "print(\"Telugu model without context:\")\n",
    "show_performance(df_telugu_answerable, predict_answerable(telugu_model, df_telugu, mbert_tokenizer, device))\n",
    "print(\"Telugu model with context:\")\n",
    "show_performance(df_telugu_answerable, predict_answerable(telugu_model_w_context, df_telugu, mbert_tokenizer, device))\n",
    "print(\"Only context model:\")\n",
    "show_performance(df_arkote_answerable, predict_answerable(context_model, df_context, mbert_tokenizer, device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
