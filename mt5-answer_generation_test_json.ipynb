{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08c80ae",
   "metadata": {},
   "source": [
    "# MT5 Fine-tuning for Question Answering\n",
    "\n",
    "This notebook demonstrates fine-tuning the MT5 model on multilingual question answering data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6bbf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e152c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from mt5_utils import generate_prompt_wo_context, tokenize_to_dataset, trainer_generator, get_extra_id_0_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9fa6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt5_telugu_w_context_save_path = os.path.join(os.path.join(\"results\", \"mt5-telugu-qa-wo-context\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1bb3846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>question</th><th>context</th><th>lang</th><th>answerable</th><th>answer_start</th><th>answer</th><th>answer_inlang</th><th>translation</th></tr><tr><td>str</td><td>str</td><td>str</td><td>bool</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Which company published the vi…</td><td>&quot;Hell&#x27;s Kitchen: The Game is a …</td><td>&quot;en&quot;</td><td>true</td><td>164</td><td>&quot;Ubisoft&quot;</td><td>&quot;Ubisoft&quot;</td><td>&quot;Which company published the vi…</td></tr><tr><td>&quot;八一大楼是什么时候完全建成的？&quot;</td><td>&quot;The first PLA main office in B…</td><td>&quot;zh&quot;</td><td>true</td><td>584</td><td>&quot;July 1999&quot;</td><td>&quot;1999年7月&quot;</td><td>&quot;When was the August 1st buildi…</td></tr><tr><td>&quot;1650ల చివరలో &#x27;Hareskoven&#x27;ను ఏ …</td><td>&quot;Hareskov was severely damaged …</td><td>&quot;te&quot;</td><td>true</td><td>37</td><td>&quot;the Swedish&quot;</td><td>&quot;స్వీడిష్&quot;</td><td>&quot;Which country damaged &#x27;Haresko…</td></tr><tr><td>&quot;ఎముక పురుగులు దేని నుండి ఆహారం…</td><td>&quot;Osedax is a genus of deep-sea …</td><td>&quot;te&quot;</td><td>true</td><td>208</td><td>&quot;whale carcasses&quot;</td><td>&quot;తిమింగల కళేబరాలు&quot;</td><td>&quot;What do boneworms feed on?&quot;</td></tr><tr><td>&quot;దోసకాయలు ఏ ఖండం నుండి ఉద్భవించ…</td><td>&quot;Considered an annual plant, th…</td><td>&quot;te&quot;</td><td>true</td><td>180</td><td>&quot;Asia&quot;</td><td>&quot;ఆసియా&quot;</td><td>&quot;Which continent did cucumbers …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌─────────────┬────────────┬──────┬────────────┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ question    ┆ context    ┆ lang ┆ answerable ┆ answer_sta ┆ answer     ┆ answer_inl ┆ translatio │\n",
       "│ ---         ┆ ---        ┆ ---  ┆ ---        ┆ rt         ┆ ---        ┆ ang        ┆ n          │\n",
       "│ str         ┆ str        ┆ str  ┆ bool       ┆ ---        ┆ str        ┆ ---        ┆ ---        │\n",
       "│             ┆            ┆      ┆            ┆ i64        ┆            ┆ str        ┆ str        │\n",
       "╞═════════════╪════════════╪══════╪════════════╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ Which       ┆ Hell's     ┆ en   ┆ true       ┆ 164        ┆ Ubisoft    ┆ Ubisoft    ┆ Which      │\n",
       "│ company     ┆ Kitchen:   ┆      ┆            ┆            ┆            ┆            ┆ company    │\n",
       "│ published   ┆ The Game   ┆      ┆            ┆            ┆            ┆            ┆ published  │\n",
       "│ the vi…     ┆ is a …     ┆      ┆            ┆            ┆            ┆            ┆ the vi…    │\n",
       "│ 八一大楼是  ┆ The first  ┆ zh   ┆ true       ┆ 584        ┆ July 1999  ┆ 1999年7月  ┆ When was   │\n",
       "│ 什么时候完  ┆ PLA main   ┆      ┆            ┆            ┆            ┆            ┆ the August │\n",
       "│ 全建成的？  ┆ office in  ┆      ┆            ┆            ┆            ┆            ┆ 1st        │\n",
       "│             ┆ B…         ┆      ┆            ┆            ┆            ┆            ┆ buildi…    │\n",
       "│ 1650ల చివరలో  ┆ Hareskov   ┆ te   ┆ true       ┆ 37         ┆ the        ┆ స్వీడిష్       ┆ Which      │\n",
       "│ 'Hareskoven ┆ was        ┆      ┆            ┆            ┆ Swedish    ┆            ┆ country    │\n",
       "│ 'ను ఏ …     ┆ severely   ┆      ┆            ┆            ┆            ┆            ┆ damaged    │\n",
       "│             ┆ damaged …  ┆      ┆            ┆            ┆            ┆            ┆ 'Haresko…  │\n",
       "│ ఎముక        ┆ Osedax is  ┆ te   ┆ true       ┆ 208        ┆ whale      ┆ తిమింగల      ┆ What do    │\n",
       "│ పురుగులు దేని ┆ a genus of ┆      ┆            ┆            ┆ carcasses  ┆ కళేబరాలు     ┆ boneworms  │\n",
       "│ నుండి ఆహారం…  ┆ deep-sea … ┆      ┆            ┆            ┆            ┆            ┆ feed on?   │\n",
       "│ దోసకాయలు ఏ    ┆ Considered ┆ te   ┆ true       ┆ 180        ┆ Asia       ┆ ఆసియా        ┆ Which      │\n",
       "│ ఖండం నుండి   ┆ an annual  ┆      ┆            ┆            ┆            ┆            ┆ continent  │\n",
       "│ ఉద్భవించ…     ┆ plant, th… ┆      ┆            ┆            ┆            ┆            ┆ did        │\n",
       "│             ┆            ┆      ┆            ┆            ┆            ┆            ┆ cucumbers  │\n",
       "│             ┆            ┆      ┆            ┆            ┆            ┆            ┆ …          │\n",
       "└─────────────┴────────────┴──────┴────────────┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_json = pl.read_json(\"test.json\")\n",
    "df_test_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d1a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Select device for training\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e66903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MT5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 512)\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading model from disk\")\n",
    "mt5_w_context_tokenizer = T5Tokenizer.from_pretrained(os.path.join(mt5_telugu_w_context_save_path, \"fine_tuned\"))\n",
    "mt5_w_context_model = MT5ForConditionalGeneration.from_pretrained(os.path.join(mt5_telugu_w_context_save_path, \"fine_tuned\"))\n",
    "mt5_w_context_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e37fba",
   "metadata": {},
   "source": [
    "# Evaluate difference between answerable and not answerable questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c714215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_json_only_answerable = df_test_json.filter(pl.col(\"answerable\") == False)\n",
    "df_test_json_only_unanswerable = df_test_json.filter(pl.col(\"answerable\") == True)\n",
    "df_test_json_only_telugu = df_test_json.filter(pl.col(\"lang\") == \"te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2085f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with context and answerable\n",
    "df_test_json_prompt_w_context_answerable = generate_prompt_wo_context(df_test_json_only_answerable)\n",
    "test_json_dataset_w_context_answerable = tokenize_to_dataset(df_test_json_prompt_w_context_answerable, mt5_w_context_tokenizer)\n",
    "\n",
    "# with context and unanswerable\n",
    "df_test_json_prompt_w_context_unanswerable = generate_prompt_wo_context(df_test_json_only_unanswerable)\n",
    "test_json_dataset_w_context_unanswerable = tokenize_to_dataset(df_test_json_prompt_w_context_unanswerable, mt5_w_context_tokenizer)\n",
    "\n",
    "# with context and only telugu\n",
    "df_test_json_prompt_w_context_telugu = generate_prompt_wo_context(df_test_json_only_telugu)\n",
    "test_json_dataset_w_context_telugu = tokenize_to_dataset(df_test_json_prompt_w_context_telugu, mt5_w_context_tokenizer)\n",
    "\n",
    "# both answerable and unanswerable\n",
    "df_test_json_prompt_w_context = generate_prompt_wo_context(df_test_json)\n",
    "test_json_dataset_w_context = tokenize_to_dataset(df_test_json_prompt_w_context, mt5_w_context_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f15bc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "average_tokens_across_devices is True but world size is 1. Setting it to False automatically.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Predictions: [[     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259  37604  77007   7596      1      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099      1      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]]\n",
      "Raw Labels: [[28125 89292  3813 22675  5259   259 75958  1660     1  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [ 7174  2479     1  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]\n",
      " [  259 15439 16163 94386     1  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100  -100\n",
      "   -100  -100  -100  -100]]\n",
      "Batch Decoded Predictions: ['.', '컴퓨터', '']\n",
      "Batch Decoded Labels: ['ముద్దుగా ఉండే ముఖం', '1999년', 'ملك الثلج']\n",
      "Predictions: [[    0     0   260     1     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    0     0   259 37604 77007  7596     1     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]\n",
      " [    0     0     1     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n",
      "Decoded Predictions: ['.', '컴퓨터', '']\n",
      "Decoded Labels: [['ముద్దుగా ఉండే ముఖం'], ['1999년'], ['ملك الثلج']]\n",
      "{'eval_loss': 14.394437789916992, 'eval_model_preparation_time': 0.0016, 'eval_bleu': 0.0, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 1.2281, 'eval_samples_per_second': 2.443, 'eval_steps_per_second': 0.814}\n"
     ]
    }
   ],
   "source": [
    "# with context and answerable\n",
    "trainer = trainer_generator(\n",
    "    model=mt5_w_context_model,\n",
    "    tokenizer=mt5_w_context_tokenizer,\n",
    "    train_dataset=test_json_dataset_w_context_answerable,\n",
    "    eval_dataset=test_json_dataset_w_context_answerable,\n",
    "    output_dir=\"tmp\",\n",
    "    epochs=1\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09cdbfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "average_tokens_across_devices is True but world size is 1. Setting it to False automatically.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[     0 250099      1      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    306      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259  29794   2742  99260   1660  89811 230175    291\n",
      "       1      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259   3687   1426      1      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099   2273      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259    277      1      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259 152545    259  26889      1      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099      1      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    574      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259  61990      1      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259    262   9770   1790      1      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099   2273      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]]\n",
      "Decoded Predictions: ['<extra_id_0>', '<extra_id_0>。', '<extra_id_0>.', '<extra_id_0> నుండి ఆహారం పొందుతాయి?', '<extra_id_0>.', '<extra_id_0> 금지', '<extra_id_0>.', '<extra_id_0>.', '<extra_id_0>؟', \"<extra_id_0> '\", '<extra_id_0> لأول مرة', '<extra_id_0>', '<extra_id_0>を', '<extra_id_0> 사고', '<extra_id_0> a Colón', '<extra_id_0>؟']\n",
      "Decoded Labels: [['Ubisoft'], ['1999年7月'], ['స్వీడిష్'], ['తిమింగల కళేబరాలు'], ['ఆసియా'], ['동성 양육에 관한 책'], ['Audi works team'], ['McLaren'], ['الفن الرقمي والرسوم المتحركة ثنائية الأبعاد'], ['محركات الأقراص ذات الحالة الصلبة'], ['الصين'], ['1936'], ['1952'], ['도호쿠 지진과 쓰나미'], ['Los Indios'], ['لويس كارول']]\n",
      "{'eval_loss': 15.786043167114258, 'eval_model_preparation_time': 0.0015, 'eval_bleu': 0.0, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 1.8505, 'eval_samples_per_second': 8.646, 'eval_steps_per_second': 1.081}\n"
     ]
    }
   ],
   "source": [
    "# with context and unanswerable\n",
    "trainer = trainer_generator(\n",
    "    model=mt5_w_context_model,\n",
    "    tokenizer=mt5_w_context_tokenizer,\n",
    "    train_dataset=test_json_dataset_w_context_unanswerable,\n",
    "    eval_dataset=test_json_dataset_w_context_unanswerable,\n",
    "    output_dir=\"tmp\",\n",
    "    epochs=1\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f38db9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "average_tokens_across_devices is True but world size is 1. Setting it to False automatically.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 19\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[     0 250099      1      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    306      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259  29794   2742  99260   1660  89811 230175    291\n",
      "       1      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259   3687   1426      1      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099   2273      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259    277      1      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259 152545    259  26889      1      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099      1      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    574      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259  61990      1      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259    262   9770   1790      1      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099   2273      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259  37604  77007   7596      1      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099      1      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]]\n",
      "Decoded Predictions: ['<extra_id_0>', '<extra_id_0>。', '<extra_id_0>.', '<extra_id_0> నుండి ఆహారం పొందుతాయి?', '<extra_id_0>.', '<extra_id_0> 금지', '<extra_id_0>.', '<extra_id_0>.', '<extra_id_0>؟', \"<extra_id_0> '\", '<extra_id_0> لأول مرة', '<extra_id_0>', '<extra_id_0>を', '<extra_id_0> 사고', '<extra_id_0> a Colón', '<extra_id_0>؟', '<extra_id_0>.', '<extra_id_0> 컴퓨터', '<extra_id_0>']\n",
      "Decoded Labels: [['Ubisoft'], ['1999年7月'], ['స్వీడిష్'], ['తిమింగల కళేబరాలు'], ['ఆసియా'], ['동성 양육에 관한 책'], ['Audi works team'], ['McLaren'], ['الفن الرقمي والرسوم المتحركة ثنائية الأبعاد'], ['محركات الأقراص ذات الحالة الصلبة'], ['الصين'], ['1936'], ['1952'], ['도호쿠 지진과 쓰나미'], ['Los Indios'], ['لويس كارول'], ['ముద్దుగా ఉండే ముఖం'], ['1999년'], ['ملك الثلج']]\n",
      "{'eval_loss': 15.322174072265625, 'eval_model_preparation_time': 0.0016, 'eval_bleu': 0.0, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 1.5704, 'eval_samples_per_second': 12.099, 'eval_steps_per_second': 1.91}\n"
     ]
    }
   ],
   "source": [
    "trainer = trainer_generator(\n",
    "    model=mt5_w_context_model,\n",
    "    tokenizer=mt5_w_context_tokenizer,\n",
    "    train_dataset=test_json_dataset_w_context,\n",
    "    eval_dataset=test_json_dataset_w_context,\n",
    "    output_dir=\"tmp\",\n",
    "    epochs=1\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1083e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "average_tokens_across_devices is True but world size is 1. Setting it to False automatically.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Predictions: [[     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    259  29794   2742  99260   1660  89811 230175    291\n",
      "       1      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0 250099    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]]\n",
      "Raw Labels: [[ 52809   8219  12135  46786      1   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100]\n",
      " [ 78456  19681   1660  67887 111233   5259  17925 128615      1   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100]\n",
      " [ 96117  94897      1   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100]\n",
      " [ 28125  89292   3813  22675   5259    259  75958   1660      1   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100   -100   -100   -100   -100   -100   -100\n",
      "    -100   -100   -100   -100]]\n",
      "Batch Decoded Predictions: ['.', 'నుండి ఆహారం పొందుతాయి?', '.', '.']\n",
      "Batch Decoded Labels: ['స్వీడిష్', 'తిమింగల కళేబరాలు', 'ఆసియా', 'ముద్దుగా ఉండే ముఖం']\n",
      "Predictions: [[     0      0    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0    259  29794   2742  99260   1660  89811 230175    291\n",
      "       1      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0    260      1      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]]\n",
      "Decoded Predictions: ['.', 'నుండి ఆహారం పొందుతాయి?', '.', '.']\n",
      "Decoded Labels: [['స్వీడిష్'], ['తిమింగల కళేబరాలు'], ['ఆసియా'], ['ముద్దుగా ఉండే ముఖం']]\n",
      "{'eval_loss': 13.78261661529541, 'eval_model_preparation_time': 0.0018, 'eval_bleu': 0.0, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 0.5546, 'eval_samples_per_second': 7.212, 'eval_steps_per_second': 1.803}\n"
     ]
    }
   ],
   "source": [
    "trainer = trainer_generator(\n",
    "    model=mt5_w_context_model,\n",
    "    tokenizer=mt5_w_context_tokenizer,\n",
    "    train_dataset=test_json_dataset_w_context_telugu,\n",
    "    eval_dataset=test_json_dataset_w_context_telugu,\n",
    "    output_dir=\"tmp\",\n",
    "    epochs=1\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b18f77e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 1650ల చివరలో 'Hareskoven'ను ఏ దేశం దెబ్బతీసింది?\n",
      "Answer: స్వీడిష్\n",
      "Generated Answer: <extra_id_0>.\n"
     ]
    }
   ],
   "source": [
    "question = df_test_json_prompt_w_context_telugu[\"prompt\"][0]\n",
    "answer = df_test_json_prompt_w_context_telugu[\"answer_inlang\"][0]\n",
    "\n",
    "inputs = mt5_w_context_tokenizer(\n",
    "    question, \n",
    "    return_tensors=\"pt\", \n",
    "    truncation=True, \n",
    "    max_length=512\n",
    "    ).to(device)    \n",
    "\n",
    "outputs = mt5_w_context_model.generate(**inputs)\n",
    "gen_answer = mt5_w_context_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Generated Answer: {gen_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57c0e00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_extra_id_0_proportion(df_test_json_prompt_w_context_telugu, mt5_w_context_tokenizer, mt5_w_context_model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
