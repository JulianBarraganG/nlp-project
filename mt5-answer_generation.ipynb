{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08c80ae",
   "metadata": {},
   "source": [
    "# MT5 Fine-tuning for Question Answering\n",
    "\n",
    "This notebook demonstrates fine-tuning the MT5 model on multilingual question answering data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e152c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datasets import load_dataset\n",
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from mt5_utils import generate_prompt_with_context, generate_prompt_wo_context, tokenize_to_dataset, trainer_generator, get_extra_id_0_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fa6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "TRAIN = False\n",
    "mt5_telugu_w_context_save_path = os.path.join(os.path.join(\"results\", \"mt5-telugu-qa-w-context\"))\n",
    "mt5_telugu_wo_context_save_path = os.path.join(os.path.join(\"results\", \"mt5-telugu-qa-wo-context\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1bb3846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (50, 7), Val size: (100, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "df_train = dataset[\"train\"].to_polars()\n",
    "df_val = dataset[\"validation\"].to_polars()\n",
    "df_te_train = df_train.filter(pl.col(\"lang\") == \"te\", pl.col(\"answer_inlang\").is_not_null())\n",
    "df_te_val = df_val.filter(pl.col(\"lang\") == \"te\", pl.col(\"answer_inlang\").is_not_null())\n",
    "\n",
    "print(f\"Train size: {df_te_train.shape}, Val size: {df_te_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985d595",
   "metadata": {},
   "source": [
    "load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d1a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Select device for training\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e66903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from disk\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(os.path.join(mt5_telugu_w_context_save_path, \"fine_tuned\")):\n",
    "    print(\"Loading model from disk\")\n",
    "    mt5_w_context_tokenizer = T5Tokenizer.from_pretrained(os.path.join(mt5_telugu_w_context_save_path, \"fine_tuned\"))\n",
    "    mt5_w_context_model = MT5ForConditionalGeneration.from_pretrained(os.path.join(mt5_telugu_w_context_save_path, \"fine_tuned\"))\n",
    "    mt5_w_context_model.to(device)\n",
    "else:\n",
    "    print(\"Loading model from Huggingface\")\n",
    "    mt5_w_context_tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
    "    mt5_w_context_model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")\n",
    "    mt5_w_context_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa6a06",
   "metadata": {},
   "source": [
    "prepare dataset fo training (with context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b38c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_te_train_prompt_w_context = generate_prompt_with_context(df_te_val) # Flip train and val since val is bigger\n",
    "df_te_val_prompt_w_context = generate_prompt_with_context(df_te_train)\n",
    "train_dataset_w_context = tokenize_to_dataset(df_te_train_prompt_w_context, mt5_w_context_tokenizer)\n",
    "val_dataset_w_context = tokenize_to_dataset(df_te_val_prompt_w_context, mt5_w_context_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97cb50f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asge1\\Downloads\\nlp-project\\mt5_utils.py:117: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.063244819641113, 'eval_model_preparation_time': 0.003, 'eval_bleu': 0.1785, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 3.746, 'eval_samples_per_second': 13.348, 'eval_steps_per_second': 1.869}\n"
     ]
    }
   ],
   "source": [
    "trainer = trainer_generator(\n",
    "    model=mt5_w_context_model,\n",
    "    tokenizer=mt5_w_context_tokenizer,\n",
    "    train_dataset=train_dataset_w_context,\n",
    "    eval_dataset=val_dataset_w_context,\n",
    "    output_dir=mt5_telugu_w_context_save_path,\n",
    "    epochs=25\n",
    ")\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "    trainer.save_model(os.path.join(mt5_telugu_w_context_save_path, \"fine_tuned\"))\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56eb7541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file tokenizer.json\n",
      "loading file chat_template.jinja\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file results\\mt5-telugu-qa-wo-context\\fine_tuned\\config.json\n",
      "Model config MT5Config {\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 1024,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 8,\n",
      "  \"num_heads\": 6,\n",
      "  \"num_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.57.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading weights file results\\mt5-telugu-qa-wo-context\\fine_tuned\\model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading configuration file results\\mt5-telugu-qa-wo-context\\fine_tuned\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": [\n",
      "    1\n",
      "  ],\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Could not locate the custom_generate/generate.py inside results\\mt5-telugu-qa-wo-context\\fine_tuned.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(os.path.join(mt5_telugu_wo_context_save_path, \"fine_tuned\")):\n",
    "    print(\"Loading model from disk\")\n",
    "    mt5_wo_context_tokenizer = T5Tokenizer.from_pretrained(os.path.join(mt5_telugu_wo_context_save_path, \"fine_tuned\"))\n",
    "    mt5_wo_context_model = MT5ForConditionalGeneration.from_pretrained(os.path.join(mt5_telugu_wo_context_save_path, \"fine_tuned\"))\n",
    "    mt5_wo_context_model.to(device)\n",
    "else:\n",
    "    print(\"Loading model from Huggingface\")\n",
    "    mt5_wo_context_tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
    "    mt5_wo_context_model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")\n",
    "    mt5_wo_context_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2fa82",
   "metadata": {},
   "source": [
    "prepare dataset fo training (without context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524b4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_te_train_prompt_wo_context = generate_prompt_wo_context(df_te_val)\n",
    "df_te_val_prompt_wo_context = generate_prompt_wo_context(df_te_train)\n",
    "train_dataset_wo_context = tokenize_to_dataset(df_te_train_prompt_wo_context, mt5_wo_context_tokenizer)\n",
    "val_dataset_wo_context = tokenize_to_dataset(df_te_val_prompt_wo_context, mt5_wo_context_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "004ba5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.946054458618164, 'eval_model_preparation_time': 0.003, 'eval_bleu': 0.1277, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 9.3689, 'eval_samples_per_second': 5.337, 'eval_steps_per_second': 0.747}\n"
     ]
    }
   ],
   "source": [
    "trainer = trainer_generator(\n",
    "    model=mt5_wo_context_model,\n",
    "    tokenizer=mt5_wo_context_tokenizer,\n",
    "    train_dataset=train_dataset_wo_context,\n",
    "    eval_dataset=val_dataset_wo_context,\n",
    "    output_dir=mt5_telugu_wo_context_save_path,\n",
    "    epochs=25\n",
    ")\n",
    "if TRAIN:\n",
    "    trainer.train()\n",
    "    trainer.save_model(os.path.join(mt5_telugu_wo_context_save_path, \"fine_tuned\"))\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7afe67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gc\n",
    "#gc.collect()\n",
    "#with torch.no_grad():\n",
    "#    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df5c6c6",
   "metadata": {},
   "source": [
    "Generate a random answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fce6e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ఆంధ్రప్రదేశ్ లో మొదటగా ఏ ఇంజనీరింగ్ కళాశాలలో సివిల్ ఇంజనీరింగ్ విభాగాన్ని ప్రారంభించారు?</s>The Indian Railways Institute of Mechanical and Electrical Engineering (IRIMEE), was founded in 1888 as a technical school and commenced training Mechanical Officers for Indian Railways in 1927. It is the oldest of the five Centralised Training Institutes (CTIs) for training officers for Indian Railways. IRIMEE is located at Jamalpur in the Munger district of Bihar, on the Patna-Bhagalpur rail route. IRIMEE provides theoretical and practical training for a four-year undergraduate degree in mechanical engineering as well as professional courses to officers and supervisors of Indian Railways. There are also courses for non-railway organizations and foreign railways. Traditionally a center\n",
      "Answer: వెలగపుడి రామకృష్ణ సిద్ధార్థ ఇంజనీరింగ్ కళాశాల\n",
      "Generated Answer: <extra_id_0>.\n"
     ]
    }
   ],
   "source": [
    "random_num = np.random.randint(0, len(df_te_val_prompt_w_context))\n",
    "\n",
    "question = df_te_val_prompt_w_context[\"prompt\"][random_num]\n",
    "answer = df_te_val_prompt_w_context[\"answer_inlang\"][random_num]\n",
    "\n",
    "inputs = mt5_w_context_tokenizer(\n",
    "    question, \n",
    "    return_tensors=\"pt\", \n",
    "    truncation=True, \n",
    "    max_length=512\n",
    "    ).to(device)    \n",
    "\n",
    "outputs = mt5_w_context_model.generate(**inputs)\n",
    "gen_answer = mt5_w_context_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Generated Answer: {gen_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e37fba",
   "metadata": {},
   "source": [
    "# Evaluate difference between answerable and not answerable questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c714215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train answerable size: (45, 7), Val answerable size: (93, 7)\n",
      "Train unanswerable size: (5, 7), Val unanswerable size: (7, 7)\n"
     ]
    }
   ],
   "source": [
    "df_te_train_only_answerable = df_te_train.filter(pl.col(\"answerable\") == False)\n",
    "df_te_val_only_answerable = df_te_val.filter(pl.col(\"answerable\") == False)\n",
    "df_te_train_only_unanswerable = df_te_train.filter(pl.col(\"answerable\") == True)\n",
    "df_te_val_only_unanswerable = df_te_val.filter(pl.col(\"answerable\") == True)\n",
    "\n",
    "print(f\"Train answerable size: {df_te_train_only_answerable.shape}, Val answerable size: {df_te_val_only_answerable.shape}\")\n",
    "print(f\"Train unanswerable size: {df_te_train_only_unanswerable.shape}, Val unanswerable size: {df_te_val_only_unanswerable.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2085f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with context and answerable\n",
    "df_te_val_prompt_w_context_answerable = generate_prompt_with_context(df_te_train_only_answerable)\n",
    "val_dataset_w_context_answerable = tokenize_to_dataset(df_te_val_prompt_w_context_answerable, mt5_w_context_tokenizer)\n",
    "\n",
    "# without context and answerable\n",
    "df_te_val_prompt_wo_context_answerable = generate_prompt_wo_context(df_te_train_only_answerable)\n",
    "val_dataset_wo_context_answerable = tokenize_to_dataset(df_te_val_prompt_wo_context_answerable, mt5_wo_context_tokenizer)\n",
    "\n",
    "# with context and unanswerable\n",
    "df_te_val_prompt_w_context_unanswerable = generate_prompt_with_context(df_te_train_only_unanswerable)\n",
    "val_dataset_w_context_unanswerable = tokenize_to_dataset(df_te_val_prompt_w_context_unanswerable, mt5_w_context_tokenizer)\n",
    "\n",
    "# without context and unanswerable\n",
    "df_te_val_prompt_wo_context_unanswerable = generate_prompt_wo_context(df_te_train_only_unanswerable)\n",
    "val_dataset_wo_context_unanswerable = tokenize_to_dataset(df_te_val_prompt_wo_context_unanswerable, mt5_wo_context_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f15bc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 45\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.996822357177734, 'eval_model_preparation_time': 0.003, 'eval_bleu': 0.1982, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 6.8359, 'eval_samples_per_second': 6.583, 'eval_steps_per_second': 0.878}\n",
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# with context and answerable\n",
    "trainer = trainer_generator(\n",
    "    model=mt5_w_context_model,\n",
    "    tokenizer=mt5_w_context_tokenizer,\n",
    "    train_dataset=val_dataset_w_context_answerable,\n",
    "    eval_dataset=val_dataset_w_context_answerable,\n",
    "    output_dir=\"tmp\",\n",
    "    epochs=1\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "print(get_extra_id_0_proportion(df_te_val_prompt_w_context_answerable, mt5_w_context_tokenizer, mt5_w_context_model, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09cdbfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 45\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.54616928100586, 'eval_model_preparation_time': 0.003, 'eval_bleu': 0.1424, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 7.4229, 'eval_samples_per_second': 6.062, 'eval_steps_per_second': 0.808}\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# without context and answerable\n",
    "trainer = trainer_generator(\n",
    "    model=mt5_wo_context_model,\n",
    "    tokenizer=mt5_wo_context_tokenizer,\n",
    "    train_dataset=val_dataset_wo_context_answerable,\n",
    "    eval_dataset=val_dataset_wo_context_answerable,\n",
    "    output_dir=\"tmp\",\n",
    "    epochs=1\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "print(get_extra_id_0_proportion(df_te_val_prompt_wo_context_answerable, mt5_wo_context_tokenizer, mt5_wo_context_model, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92eb2729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 14.556205749511719, 'eval_model_preparation_time': 0.003, 'eval_bleu': 0.0, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 0.5474, 'eval_samples_per_second': 9.134, 'eval_steps_per_second': 1.827}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# with context and unanswerable\n",
    "trainer = trainer_generator(\n",
    "    model=mt5_w_context_model,\n",
    "    tokenizer=mt5_w_context_tokenizer,\n",
    "    train_dataset=val_dataset_w_context_unanswerable,\n",
    "    eval_dataset=val_dataset_w_context_unanswerable,\n",
    "    output_dir=\"tmp\",\n",
    "    epochs=1\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "print(get_extra_id_0_proportion(df_te_val_prompt_w_context_unanswerable, mt5_w_context_tokenizer, mt5_w_context_model, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "429167dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 20.817989349365234, 'eval_model_preparation_time': 0.003, 'eval_bleu': 0.0, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 0.6666, 'eval_samples_per_second': 7.501, 'eval_steps_per_second': 1.5}\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# without context and unanswerable\n",
    "trainer = trainer_generator(\n",
    "    model=mt5_wo_context_model,\n",
    "    tokenizer=mt5_wo_context_tokenizer,\n",
    "    train_dataset=val_dataset_wo_context_unanswerable,\n",
    "    eval_dataset=val_dataset_wo_context_unanswerable,\n",
    "    output_dir=\"tmp\",\n",
    "    epochs=1\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "print(get_extra_id_0_proportion(df_te_val_prompt_wo_context_unanswerable, mt5_wo_context_tokenizer, mt5_wo_context_model, device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
