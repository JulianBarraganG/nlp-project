{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05d5f30",
   "metadata": {},
   "source": [
    "# LM for QA Tidy_XOR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d842b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from data.const import ARB_CACHE, KOR_CACHE, TELU_CACHE\n",
    "from nlm.models import BiLSTMLanguageModel\n",
    "from nlm.train_utils import train\n",
    "from nlm.probs import sentence_log_probability, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "mbert_model = AutoModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "pretrained_embeddings = mbert_model.get_input_embeddings().weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b991ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataloader_generator(dataset: list, tokenizer, device, test_split: float = 0.2, batch_size: int = 8) -> tuple[DataLoader, DataLoader]:\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        dataset,\n",
    "        truncation=True,\n",
    "        max_length=65,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    input_lens = attention_mask.sum(dim=1)\n",
    "\n",
    "    # Shift input_ids for targets\n",
    "    targets = input_ids.clone()\n",
    "    targets[:, :-1] = input_ids[:, 1:]\n",
    "    targets[:, -1] = tokenizer.pad_token_id\n",
    "\n",
    "    # Split into train and validation sets\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        range(input_ids.size(0)), test_size=test_split, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = TensorDataset(\n",
    "        input_ids[train_idx], input_lens[train_idx], targets[train_idx]\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        input_ids[val_idx], input_lens[val_idx], targets[val_idx]\n",
    "    )\n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dl, val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976116c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_model_loader(dataset: list, device, model_cache_path: str, epochs: int, model_lstm_dim: int = 100) -> tuple[BiLSTMLanguageModel, float, float]:\n",
    "    model = BiLSTMLanguageModel(\n",
    "        pretrained_embeddings=torch.FloatTensor(pretrained_embeddings),\n",
    "        lstm_dim=model_lstm_dim\n",
    "    ).to(device)\n",
    "\n",
    "    if os.path.exists(model_cache_path):\n",
    "        model.load_state_dict(torch.load(model_cache_path))\n",
    "    else:\n",
    "        print(\"No cached model found. Training a new model.\")\n",
    "        train_dl, val_dl = dataloader_generator(dataset, mbert_tokenizer, device)\n",
    "        losses, best_acc = train(model, train_dl, val_dl, torch.optim.Adam(model.parameters(), lr=1e-3), n_epochs=epochs, device=device, save_path=model_cache_path)\n",
    "        print('Training complete. Best validation accuracy:', best_acc)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c122a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabic dataset\n",
    "arabic_model_path = \"cached_data/bilstm_lm_arabic\"\n",
    "df_ar = pl.read_parquet(ARB_CACHE)\n",
    "df_arabic = df_ar[\"question\"].to_list()\n",
    "\n",
    "arabic_model = ml_model_loader(df_arabic, device, arabic_model_path, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86629806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korean dataset\n",
    "korean_model_path = \"cached_data/bilstm_lm_korean\"\n",
    "df_ko = pl.read_parquet(KOR_CACHE)\n",
    "df_korean = df_ko[\"question\"].to_list()\n",
    "\n",
    "korean_model = ml_model_loader(df_korean, device, korean_model_path, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telughu dataset\n",
    "telugu_model_path = \"cached_data/bilstm_lm_telugu\"\n",
    "df_telu = pl.read_parquet(TELU_CACHE)\n",
    "df_telugu = df_telu[\"question\"].to_list()\n",
    "\n",
    "telugu_model = ml_model_loader(df_telugu, device, telugu_model_path, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context dataset\n",
    "df_arkote = pl.concat([\n",
    "    df_ar,\n",
    "    df_ko,\n",
    "    df_telu\n",
    "])\n",
    "\n",
    "context_model_path = \"cached_data/bilstm_lm_context\"\n",
    "df_context = df_arkote[\"context\"].to_list()\n",
    "context_model = ml_model_loader(df_context, device, context_model_path, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f774d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_stc = \"I am Sam\"\n",
    "sentence_log_probability(context_model, device, mbert_tokenizer, tst_stc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a6150",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplex_korean = perplexity(\n",
    "    korean_model, \n",
    "    device,\n",
    "    mbert_tokenizer,\n",
    "    df_korean,\n",
    ")\n",
    "print(f\"Perplexity of the Korean text: {perplex_korean}\")\n",
    "\n",
    "perplex_telugu = perplexity(\n",
    "    telugu_model, \n",
    "    device,\n",
    "    mbert_tokenizer,\n",
    "    df_telugu,\n",
    ")\n",
    "print(f\"Perplexity of the Telugu text: {perplex_telugu}\")\n",
    "\n",
    "perplex_arabic = perplexity(\n",
    "    arabic_model, \n",
    "    device,\n",
    "    mbert_tokenizer,\n",
    "    df_arabic,\n",
    ")\n",
    "print(f\"Perplexity of the Arabic text: {perplex_arabic}\")\n",
    "\n",
    "perplex_context = perplexity(\n",
    "    context_model, \n",
    "    device,\n",
    "    mbert_tokenizer,\n",
    "    df_context,\n",
    ")\n",
    "print(f\"Perplexity of the Context text: {perplex_context}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
