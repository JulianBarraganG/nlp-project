{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c643ea4c",
   "metadata": {},
   "source": [
    "# LM for QA Tidy_XOR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d6106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from transformers import AutoTokenizer\n",
    "from data.const import ARB_CACHE, KOR_CACHE, TELU_CACHE\n",
    "from typing import TypeAlias\n",
    "from ngrams.utils import (\n",
    "    TokenizedSentences,\n",
    "    NGramsDict,\n",
    "    DataInconsistencyError,\n",
    "    train_test_split_and_tokenize,\n",
    "    get_ngrams_dict,\n",
    "    get_ngrams_dict_from_sentences,\n",
    "    tokenize,\n",
    ")\n",
    "from ngrams.models import NGramLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arkote = pl.concat([\n",
    "    pl.read_parquet(ARB_CACHE),\n",
    "    pl.read_parquet(KOR_CACHE),\n",
    "    pl.read_parquet(TELU_CACHE)\n",
    "])\n",
    "df_ko_mini = pl.read_parquet(KOR_CACHE)[:100]\n",
    "df_ko_mini.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ko_mini.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ccf7c8",
   "metadata": {},
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa4a02",
   "metadata": {},
   "source": [
    "### Examine the corpus stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average context length\n",
    "context = df_arkote[\"context\"]\n",
    "avg_len = sum(len(c) for c in context) / len(context)\n",
    "print(f\"Average context length: {avg_len:.2f} characters\")\n",
    "print(f\"Number of sequences (rows) in context: {len(context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get english corpus\n",
    "context_corpus = df_arkote[\"context\"].to_list()\n",
    "# Get number of unique space seperated words (not tokens)\n",
    "context_vocab = set(\" \".join(context_corpus).split())\n",
    "number_of_unique_words = len(context_vocab)\n",
    "print(f\"Number of unique (space seperated) words in context: {number_of_unique_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898097cd",
   "metadata": {},
   "source": [
    "### Tokenize corpus\n",
    "Here we use Multilingual BERT tokenizer. We use identical tokenizer for comparing perplexity.\n",
    "Each string entrance may be several sentences, but for simplicity we are gonna treat each one as a single sequence, and use the inherent start- and end-of-sentence markers from mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multilingual bert tokenizer\n",
    "mbert = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "mbert.add_tokens([\"<s>\", \"</s>\"])  # Add start and end tokens\n",
    "\n",
    "# Example tokenization\n",
    "sample_content_tokens = tokenize(df_arkote[\"context\"][10], n=5)\n",
    "print(f\"Sample content tokens (n=5):\")\n",
    "\" | \".join(sample_content_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de37518",
   "metadata": {},
   "source": [
    "## N-Gram LM\n",
    "First we explore some statistics of $n$, to pick the size we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25eea4a",
   "metadata": {},
   "source": [
    "### Examine NGramDicts for context series for N={1, 2, 3, 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine unigrams for train\n",
    "n1_context_train, n1_context_test = train_test_split_and_tokenize(context, verbose=True)\n",
    "print(\"Getting unigrams...\")\n",
    "unigrams = get_ngrams_dict_from_sentences(n1_context_train, 1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a047453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine bigrams for train\n",
    "n2_context_train, n2_context_test = train_test_split_and_tokenize(context, n=2, verbose=True)\n",
    "print(\"Getting bigrams...\")\n",
    "bigrams = get_ngrams_dict_from_sentences(n2_context_train, 2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine trigrams for train\n",
    "n3_context_train, n3_context_test = train_test_split_and_tokenize(context, n=3, verbose=True)\n",
    "print(\"Getting trigrams...\")\n",
    "trigrams = get_ngrams_dict_from_sentences(n3_context_train, 3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6cbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine 4-grams for train\n",
    "n4_context_train, n4_context_test = train_test_split_and_tokenize(context, n=4, verbose=True)\n",
    "print(\"Getting fourgrams...\")\n",
    "fourgrams = get_ngrams_dict_from_sentences(n4_context_train, 4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68133a36",
   "metadata": {},
   "source": [
    "### NGramModel from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a115791",
   "metadata": {},
   "source": [
    "## Verifying correctness of NGramModel\n",
    "First we regenerate probabilities from example in SLP book, then we verify our model against it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c5aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_series = pl.Series([\"I am Sam\", \"Sam I am\", \"I do not like green eggs and ham\"])\n",
    "cased_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "cased_tokenizer.add_tokens([\"<s>\", \"</s>\"])  # Add start and end tokens\n",
    "ngram_ready_tokens = [tokenize(seq, tokenizer=cased_tokenizer.tokenize, n=2) for seq in mock_series]\n",
    "mock_data = ngram_ready_tokens # work for both uni- and bigrams\n",
    "mock_nm1grams = get_ngrams_dict_from_sentences(mock_data, 1, verbose=True)\n",
    "mock_ngrams = get_ngrams_dict_from_sentences(mock_data, 2, verbose=True)\n",
    "for row in mock_data:\n",
    "    print(\" | \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b56fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = NGramLM(mock_nm1grams, mock_ngrams, smoothing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "mock_sentence = \"I am Sam\"\n",
    "mock_sentence = tokenize(mock_sentence, tokenizer=cased_tokenizer.tokenize, n=2)\n",
    "bigram_mock_sentence = list(nltk.ngrams(mock_sentence, 2))\n",
    "# Should ignore \"b\" as it is OOV and return 2/3 * 2/3 * 1/2 * 1/2 = 1/9 = 0.1111\n",
    "print(bigram_model.get_sentence_probability(bigram_mock_sentence, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f790d",
   "metadata": {},
   "source": [
    "Count num words via ngrams (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get N for bi, tri and fourgrams\n",
    "#for n in [2, 3, 4]:\n",
    "#    ngram_ready_tokens = [tokenize(seq, tokenizer=cased_tokenizer.tokenize, n=n) for seq in mock_series]\n",
    "#    ngram_mock_sentences = [list(nltk.ngrams(seq, n)) for seq in ngram_ready_tokens]\n",
    "#    print(f\"Sample ngram: {ngram_mock_sentences[0] if ngram_mock_sentences else None}\")\n",
    "#    # Should match num tokens excluding <s>\n",
    "#    print(f\"Len of sample ngram (sanity check): {len(ngram_mock_sentences[0])}\")\n",
    "#    N = sum([len(sentence) for sentence in ngram_mock_sentences]) - len(ngram_mock_sentences)\n",
    "#    print(f\"N for {n}-grams: {N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ac439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity of mock example\n",
    "ngram_ready_tokens = [tokenize(seq, tokenizer=cased_tokenizer.tokenize, n=2) for seq in mock_series]\n",
    "bigram_mock_sentences = [list(nltk.ngrams(seq, 2)) for seq in ngram_ready_tokens]\n",
    "# Mock sentence [\"<s>\", \"I\", \"am\", \"Sam\", \"</s>\"], seq prob = 1/9  (not counting <s>)\n",
    "# thus perplexity = (1/9)^(-1/4) = sqrt(3) approx 1.732\n",
    "print(bigram_model.get_perplexity([bigram_mock_sentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe3a93",
   "metadata": {},
   "source": [
    "## Get Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21fa2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import nltk\n",
    "from transformers import AutoTokenizer\n",
    "from data.const import ARB_CACHE, KOR_CACHE, TELU_CACHE\n",
    "from typing import TypeAlias, cast\n",
    "\n",
    "NGram = tuple[str, ...]\n",
    "Tokens: TypeAlias = list[str]\n",
    "TokenizedSentences: TypeAlias = list[Tokens]\n",
    "NGramsDict: TypeAlias = dict[NGram, int]\n",
    "ModelReadyData: TypeAlias = tuple[NGramsDict, NGramsDict, list[list[NGram]]]\n",
    "\n",
    "def get_model_ready_data(corpus: pl.Series, n: int) -> ModelReadyData:\n",
    "    \"\"\"One function to call on relevant series, to get NGramModel ready data\"\"\"\n",
    "    x_train, x_test = train_test_split_and_tokenize(corpus, n=n)\n",
    "    nm1grams_dict = get_ngrams_dict_from_sentences(x_train, n-1, verbose=False)\n",
    "    ngrams_dict = get_ngrams_dict_from_sentences(x_train, n, verbose=False)\n",
    "    # Make test into list of ngram sentences\n",
    "    x_test = list([list(nltk.ngrams(sentence, n)) for sentence in x_test])\n",
    "    x_test = cast(list[list[NGram]], x_test)  # Type hinting for clarity\n",
    "    data = cast(ModelReadyData, (nm1grams_dict, ngrams_dict, x_test))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram, bigram, test = get_model_ready_data(df_arkote[\"context\"], 2)\n",
    "content_bigram_model = NGramLM(unigram, bigram, smoothing=\"laplace\")\n",
    "content_model_perplexity = content_bigram_model.get_perplexity(test)\n",
    "print(f\"Content bigram LM perplexity: {content_model_perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85399e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram, trigram, test = get_model_ready_data(df_arkote[\"context\"], 3)\n",
    "content_trigram_model = NGramLM(bigram, trigram, smoothing=\"laplace\")\n",
    "content_trigram_model_perplexity = content_trigram_model.get_perplexity(test)\n",
    "print(f\"Content trigram LM perplexity: {content_trigram_model_perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743425e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram, fourgram, test = get_model_ready_data(df_arkote[\"context\"], 4)\n",
    "content_fourgram_model = NGramLM(trigram, fourgram, smoothing=\"laplace\")\n",
    "content_fourgram_model_perplexity = content_fourgram_model.get_perplexity(test)\n",
    "print(f\"Content fourgram LM perplexity: {content_fourgram_model_perplexity:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
