{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c643ea4c",
   "metadata": {},
   "source": [
    "# LM for QA Tidy_XOR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d6106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import nltk\n",
    "from transformers import AutoTokenizer\n",
    "from data.const import ARB_CACHE, KOR_CACHE, TELU_CACHE\n",
    "from typing import TypeAlias\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arkote = pl.concat([\n",
    "    pl.read_parquet(ARB_CACHE),\n",
    "    pl.read_parquet(KOR_CACHE),\n",
    "    pl.read_parquet(TELU_CACHE)\n",
    "])\n",
    "df_ko_mini = pl.read_parquet(KOR_CACHE)[:100]\n",
    "df_ko_mini.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ko_mini.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ccf7c8",
   "metadata": {},
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1615018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa4a02",
   "metadata": {},
   "source": [
    "### Get corpus as one long string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average context length\n",
    "context = df_arkote[\"context\"]\n",
    "avg_len = sum(len(c) for c in context) / len(context)\n",
    "print(f\"Average context length: {avg_len:.2f} characters\")\n",
    "len(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get english corpus\n",
    "context_corpus = df_arkote[\"context\"].str.join(\"\\n\")[0]\n",
    "context_vocab = set(context_corpus)\n",
    "print(f\"Number of characters in corpus: {len(context_corpus):,}\")\n",
    "print(f\"Vocalulary size: {len(context_vocab):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898097cd",
   "metadata": {},
   "source": [
    "### Tokenize corpus\n",
    "Here we use Multilingual BERT tokenizer. We use identical tokenizer for comparing perplexity.\n",
    "Each string entrance may be several sentences, but for simplicity we are gonna treat each one as a single sequence, and use the inherent start- and end-of-sentence markers from mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multilingual bert tokenizer\n",
    "mbert = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "mbert.add_tokens([\"<s>\", \"</s>\"])  # Add start and end tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19064d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = (\"<s>\" + df_arkote[\"context\"] + \"</s>\").to_list()\n",
    "context_tokenized = [mbert.tokenize(c) for c in context]\n",
    "# Example tokenization\n",
    "\" | \".join(context_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tokens(token_lists: list[list[str]]) -> list[str]:\n",
    "    \"\"\"Unnest list of lists (one of most efficient methods with .extend())\"\"\"\n",
    "    flattened = []\n",
    "    for token_list in token_lists:\n",
    "        flattened.extend(token_list)\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b632075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, val, test\n",
    "train_index = int(len(context_tokenized) * 0.7)\n",
    "raw_context_train = context_tokenized[:train_index]\n",
    "raw_context_test = context_tokenized[train_index:]\n",
    "context_train = flatten_tokens(raw_context_train)\n",
    "context_test = flatten_tokens(raw_context_test)\n",
    "print(f\"Train size: {len(context_train):>15,} tokens.\")\n",
    "print(f\"Test size: {len(context_test):>16,} tokens.\")\n",
    "print(f\"Total corpus size: {len(context_train) + len(context_test):>8,} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de37518",
   "metadata": {},
   "source": [
    "## N-Gram LM\n",
    "First we explore some statistics of $n$, to pick the size we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGramsDict: TypeAlias = dict[tuple[str, ...], int]\n",
    "def get_ngrams_dict(\n",
    "    tokens: list[str],\n",
    "    n: int,\n",
    "    verbose: bool = False,\n",
    ") -> NGramsDict:\n",
    "    \"\"\"Get n-grams count dictionary from list of tokens.\"\"\"\n",
    "    n_grams_gen = nltk.ngrams(tokens, n)\n",
    "    count_dict = {}\n",
    "    num_duplicates = 0\n",
    "    for gram in n_grams_gen:\n",
    "        if gram in count_dict:\n",
    "            count_dict[gram] += 1\n",
    "            num_duplicates += 1\n",
    "            if verbose and num_duplicates <= 5:\n",
    "                print(\"Duplicate gram found: \", gram)\n",
    "            if verbose and num_duplicates == 6:\n",
    "                print(\"...\")  # Indicate more duplicates exist\n",
    "        else:\n",
    "            count_dict[gram] = 1\n",
    "    if verbose:\n",
    "        print(f\"Number of unique {n}-grams:  {len(count_dict):,}\")\n",
    "        print(f\"Total number of {n}-grams:  {sum(count_dict.values()):,}\")\n",
    "        print(f\"Number of duplicate {n}-grams encountered:  {num_duplicates:,}\")\n",
    "        assert num_duplicates == sum(count_dict.values()) - len(count_dict), \"Duplicate count mismatch!\"\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine unigrams for train\n",
    "unigrams = get_ngrams_dict(context_train, 1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a047453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine bigrams for train\n",
    "bigrams = get_ngrams_dict(context_train, 2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine trigrams for train\n",
    "trigrams = get_ngrams_dict(context_train, 3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6cbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine 4-grams for train\n",
    "fourgrams = get_ngrams_dict(context_train, 4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6febe85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SeqProbDict: TypeAlias = dict[tuple[str, ...], float]\n",
    "class DataInconsistencyError(Exception):\n",
    "    \"\"\"Custom error for data inconsistency issues.\"\"\"\n",
    "\n",
    "class NGramModel:\n",
    "    \"\"\"Class to represent an N-gram language model.\n",
    "    The model takes as input the n-grams and (n-1)-grams count dictionaries,\n",
    "    and computes the conditional probabilities of the n-grams given the (n-1)-grams. \n",
    "    \"\"\"\n",
    "    def __init__(self, nm1grams: NGramsDict, ngrams: NGramsDict, vocabulary: set[str], alpha: float = 1.0):\n",
    "        self.ngrams = ngrams\n",
    "        self.nm1grams = nm1grams\n",
    "        self.n = len(list(ngrams.keys())[0])\n",
    "        self.alpha = alpha\n",
    "        self.vocabulary = vocabulary\n",
    "        self.vocab_size = len(vocabulary)\n",
    "        self.probabilities = self._compute_probabilities()\n",
    "\n",
    "    def _compute_probabilities(self) -> SeqProbDict:\n",
    "        \"\"\"Compute the conditional probabilities of the n-grams given the (n-1)-grams.\"\"\"\n",
    "        probabilities_dict = {}\n",
    "        for gram in self.ngrams:\n",
    "            nm1gram = gram[:-1]\n",
    "            probabilities_dict[gram] = (self.ngrams[gram] + self.alpha) / (self.nm1grams[nm1gram] + self.alpha * self.vocab_size)\n",
    "\n",
    "        return probabilities_dict\n",
    "\n",
    "    def get_text_log_prob(self, text: list[str]) -> float:\n",
    "            \"\"\"Get the probability of a given text sequence (input as list of tokens).\"\"\"\n",
    "            log_prob = 0.0\n",
    "            for ngram in nltk.ngrams(text, self.n):\n",
    "                if ngram in self.probabilities:\n",
    "                    prob = self.probabilities[ngram]\n",
    "                else:\n",
    "                    prob = 1e-10  # Very small probability for completely unseen context\n",
    "                if prob <= 0:\n",
    "                    prob = 1e-10  # Avoid log(0)\n",
    "                log_prob += np.log(prob)\n",
    "                \n",
    "            return log_prob\n",
    "    def get_text_prob(self, text: list[str]) -> float:\n",
    "        return np.exp(self.get_text_log_prob(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e58054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(context_train)\n",
    "model = NGramModel(unigrams, bigrams, vocab, alpha=10.0)\n",
    "total_train_prob = sum([np.exp(model.get_text_log_prob(text)) for text in raw_context_train])\n",
    "total_test_prob = sum([np.exp(model.get_text_log_prob(text)) for text in raw_context_test])\n",
    "print(f\"Total train probability: {total_train_prob}\")\n",
    "print(f\"Total test probability: {total_test_prob}\")\n",
    "single_prob = model.get_text_log_prob(raw_context_test[0])\n",
    "print(f\"Single test sequence log probability: {single_prob}\")\n",
    "print(f\"Single test sequence probability: {np.exp(single_prob)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
