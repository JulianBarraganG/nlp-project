{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d681fbb",
   "metadata": {},
   "source": [
    "## Weak 36. Exploring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f93c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    pipeline,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import polars as pl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e76ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get huggingface dataset\n",
    "dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "df_train = pl.from_pandas(dataset[\"train\"].to_pandas())\n",
    "df_val = pl.from_pandas(dataset[\"validation\"].to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88bb540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>question</th><th>context</th><th>lang</th><th>answerable</th><th>answer_start</th><th>answer</th><th>answer_inlang</th></tr><tr><td>str</td><td>str</td><td>str</td><td>bool</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;উইকিলিকস কত সালে সর্বপ্রথম ইন্…</td><td>&quot;WikiLeaks () is an internation…</td><td>&quot;bn&quot;</td><td>true</td><td>182</td><td>&quot;2006&quot;</td><td>null</td></tr><tr><td>&quot;দ্বিতীয় বিশ্বযুদ্ধে কোন দেশ প…</td><td>&quot;The war in Europe concluded wi…</td><td>&quot;bn&quot;</td><td>true</td><td>48</td><td>&quot;Germany&quot;</td><td>null</td></tr><tr><td>&quot;মার্কিন যুক্তরাষ্ট্রের সংবিধান…</td><td>&quot;Same-sex marriage in the Unite…</td><td>&quot;bn&quot;</td><td>false</td><td>-1</td><td>&quot;no&quot;</td><td>null</td></tr><tr><td>&quot;আরব-ইসরায়েলি যুদ্ধে আরবের মোট…</td><td>&quot;The exact number of Arab casua…</td><td>&quot;bn&quot;</td><td>true</td><td>39</td><td>&quot;unknown&quot;</td><td>null</td></tr><tr><td>&quot;বিশ্বে প্রথম পুঁজিবাদী সমাজ কব…</td><td>&quot;As Thomas Hall (2000) notes, &quot;…</td><td>&quot;bn&quot;</td><td>true</td><td>1219</td><td>&quot;17th century&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌────────────────┬───────────────┬──────┬────────────┬──────────────┬──────────────┬───────────────┐\n",
       "│ question       ┆ context       ┆ lang ┆ answerable ┆ answer_start ┆ answer       ┆ answer_inlang │\n",
       "│ ---            ┆ ---           ┆ ---  ┆ ---        ┆ ---          ┆ ---          ┆ ---           │\n",
       "│ str            ┆ str           ┆ str  ┆ bool       ┆ i64          ┆ str          ┆ str           │\n",
       "╞════════════════╪═══════════════╪══════╪════════════╪══════════════╪══════════════╪═══════════════╡\n",
       "│ উইকিলিকস কত    ┆ WikiLeaks ()  ┆ bn   ┆ true       ┆ 182          ┆ 2006         ┆ null          │\n",
       "│ সালে সর্বপ্রথম    ┆ is an         ┆      ┆            ┆              ┆              ┆               │\n",
       "│ ইন্…            ┆ internation…  ┆      ┆            ┆              ┆              ┆               │\n",
       "│ দ্বিতীয়         ┆ The war in    ┆ bn   ┆ true       ┆ 48           ┆ Germany      ┆ null          │\n",
       "│ বিশ্বযুদ্ধে কোন   ┆ Europe        ┆      ┆            ┆              ┆              ┆               │\n",
       "│ দেশ প…         ┆ concluded wi… ┆      ┆            ┆              ┆              ┆               │\n",
       "│ মার্কিন          ┆ Same-sex      ┆ bn   ┆ false      ┆ -1           ┆ no           ┆ null          │\n",
       "│ যুক্তরাষ্ট্রের      ┆ marriage in   ┆      ┆            ┆              ┆              ┆               │\n",
       "│ সংবিধান…        ┆ the Unite…    ┆      ┆            ┆              ┆              ┆               │\n",
       "│ আরব-ইসরায়েলি    ┆ The exact     ┆ bn   ┆ true       ┆ 39           ┆ unknown      ┆ null          │\n",
       "│ যুদ্ধে আরবের     ┆ number of     ┆      ┆            ┆              ┆              ┆               │\n",
       "│ মোট…           ┆ Arab casua…   ┆      ┆            ┆              ┆              ┆               │\n",
       "│ বিশ্বে প্রথম     ┆ As Thomas     ┆ bn   ┆ true       ┆ 1219         ┆ 17th century ┆ null          │\n",
       "│ পুঁজিবাদী সমাজ কব… ┆ Hall (2000)   ┆      ┆            ┆              ┆              ┆               │\n",
       "│                ┆ notes, \"…     ┆      ┆            ┆              ┆              ┆               │\n",
       "└────────────────┴───────────────┴──────┴────────────┴──────────────┴──────────────┴───────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5712570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = df_train.filter(pl.col(\"lang\") == \"ar\")\n",
    "df_ko = df_train.filter(pl.col(\"lang\") == \"ko\")\n",
    "df_te = df_train.filter(pl.col(\"lang\") == \"te\")\n",
    "df_arkote = df_train.filter(pl.col(\"lang\").is_in([\"ar\", \"ko\", \"te\"]))\n",
    "assert df_ar.height + df_ko.height + df_te.height == df_arkote.height; # sanity check\n",
    "\n",
    "df_ar_val = df_val.filter(pl.col(\"lang\") == \"ar\")\n",
    "df_ko_val = df_val.filter(pl.col(\"lang\") == \"ko\")\n",
    "df_te_val = df_val.filter(pl.col(\"lang\") == \"te\")\n",
    "df_arkote_val = df_val.filter(pl.col(\"lang\").is_in([\"ar\", \"ko\", \"te\"]))\n",
    "assert df_ar_val.height + df_ko_val.height + df_te_val.height == df_arkote_val.height; # sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5f20f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>question</th><th>context</th><th>lang</th><th>answerable</th><th>answer_start</th><th>answer</th><th>answer_inlang</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;6335&quot;</td><td>&quot;6335&quot;</td><td>&quot;6335&quot;</td><td>6335.0</td><td>6335.0</td><td>&quot;6335&quot;</td><td>&quot;50&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;6285&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>null</td><td>0.942699</td><td>155.155012</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>225.380919</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;&#x27;과학혁명의 구조&#x27;내용은 무엇인가?&quot;</td><td>&quot;\n",
       "Gerschenkron did not define e…</td><td>&quot;ar&quot;</td><td>0.0</td><td>-1.0</td><td>&quot;&quot;A Portuguesa&quot;&quot;</td><td>&quot;(100 °సెం.)&quot;</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14.0</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>78.0</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>208.0</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;힌두교의 정통 철학은 총 몇개인가?&quot;</td><td>&quot;Ṭāriq ibn Ziyād () was a Musli…</td><td>&quot;te&quot;</td><td>1.0</td><td>3964.0</td><td>&quot;“marry-your-rapist” laws&quot;</td><td>&quot;సి.ఎన్.అన్నాదురై&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 8)\n",
       "┌────────────┬─────────────┬────────────┬──────┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ statistic  ┆ question    ┆ context    ┆ lang ┆ answerable ┆ answer_sta ┆ answer     ┆ answer_inl │\n",
       "│ ---        ┆ ---         ┆ ---        ┆ ---  ┆ ---        ┆ rt         ┆ ---        ┆ ang        │\n",
       "│ str        ┆ str         ┆ str        ┆ str  ┆ f64        ┆ ---        ┆ str        ┆ ---        │\n",
       "│            ┆             ┆            ┆      ┆            ┆ f64        ┆            ┆ str        │\n",
       "╞════════════╪═════════════╪════════════╪══════╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ count      ┆ 6335        ┆ 6335       ┆ 6335 ┆ 6335.0     ┆ 6335.0     ┆ 6335       ┆ 50         │\n",
       "│ null_count ┆ 0           ┆ 0          ┆ 0    ┆ 0.0        ┆ 0.0        ┆ 0          ┆ 6285       │\n",
       "│ mean       ┆ null        ┆ null       ┆ null ┆ 0.942699   ┆ 155.155012 ┆ null       ┆ null       │\n",
       "│ std        ┆ null        ┆ null       ┆ null ┆ null       ┆ 225.380919 ┆ null       ┆ null       │\n",
       "│ min        ┆ '과학혁명의 ┆            ┆ ar   ┆ 0.0        ┆ -1.0       ┆ \"A Portugu ┆ (100 °సెం.) │\n",
       "│            ┆ 구조'내용은 ┆ Gerschenkr ┆      ┆            ┆            ┆ esa\"       ┆            │\n",
       "│            ┆ 무엇인가?   ┆ on did not ┆      ┆            ┆            ┆            ┆            │\n",
       "│            ┆             ┆ define e…  ┆      ┆            ┆            ┆            ┆            │\n",
       "│ 25%        ┆ null        ┆ null       ┆ null ┆ null       ┆ 14.0       ┆ null       ┆ null       │\n",
       "│ 50%        ┆ null        ┆ null       ┆ null ┆ null       ┆ 78.0       ┆ null       ┆ null       │\n",
       "│ 75%        ┆ null        ┆ null       ┆ null ┆ null       ┆ 208.0      ┆ null       ┆ null       │\n",
       "│ max        ┆ 힌두교의    ┆ Ṭāriq ibn  ┆ te   ┆ 1.0        ┆ 3964.0     ┆ “marry-you ┆ సి.ఎన్.అన్నాదు │\n",
       "│            ┆ 정통 철학은 ┆ Ziyād ()   ┆      ┆            ┆            ┆ r-rapist”  ┆ రై          │\n",
       "│            ┆ 총          ┆ was a      ┆      ┆            ┆            ┆ laws       ┆            │\n",
       "│            ┆ 몇개인가?   ┆ Musli…     ┆      ┆            ┆            ┆            ┆            │\n",
       "└────────────┴─────────────┴────────────┴──────┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arkote.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ed480",
   "metadata": {},
   "source": [
    "### Get tokenizers and look at sample (Arabic) sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466187e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multilingual BERT tokenizer\n",
    "mbert_tokenizer = Tokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "# Load GPT-4 tokenizer\n",
    "gpt4_tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "# Load NLLB-200 tokenizer\n",
    "nllb_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b133cb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] | పరపంచ | ##ంల | మ | ##టట | ##మ | ##ద | ##ట | ద | ##ూర | వదయ | వదయ | ##లయం | ఏ | ద | ##శం | ##ల | స | ##థ | ##ప | ##ంచ | ##బడంద | ? | [SEP]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT tokenization example\n",
    "\" | \".join(mbert_tokenizer.encode(df_te[\"question\"][0]).tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a80d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'� | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � |   |  � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � |  � | � | � | � | � | � |  � | � | � | � | � | � | � | � | � | � |  � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � |  � | � |  � | � | � | � | � | � | � | � | � | � | � | � |  � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � | � |  ?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode each token from GPT-4 tokenizer\n",
    "\" | \".join([gpt4_tokenizer.decode([token]) for token in gpt4_tokenizer.encode(df_te[\"question\"][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e331fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁ప్రపంచంలో | ▁మొట్టమొదటి | ▁దూ | ర | ▁విద్య | ▁విద్య | ాల | యం | ▁ఏ | ▁దేశంలో | ▁స్థా | పించ | బడింది | ▁?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLLB-200 tokenization example\n",
    "\" | \".join(nllb_tokenizer.tokenize(df_te[\"question\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955647f",
   "metadata": {},
   "source": [
    "## Get the top 5 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1168e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language dict\n",
    "lang_dict = {\n",
    "    \"ar\": \"arb_Arab\",\n",
    "    \"ko\": \"kor_Hang\",\n",
    "    \"te\": \"tel_Telu\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0adf1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up translation pipeline for NLLB-200\n",
    "translator_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a606491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Who is the winner of the Thirty Years' War?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example translation\n",
    "random_txt = df_ko[\"question\"][0]\n",
    "translator = translator = pipeline(\n",
    "        \"translation\",\n",
    "        model=translator_model,\n",
    "        tokenizer=nllb_tokenizer,\n",
    "        src_lang=\"kor_Hang\",\n",
    "        tgt_lang=\"eng_Latn\",\n",
    "    )\n",
    "translator(random_txt)[0][\"translation_text\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab4ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_translator(src_lang:str):\n",
    "    translator = pipeline(\n",
    "        \"translation\",\n",
    "        model=translator_model,\n",
    "        tokenizer=nllb_tokenizer,\n",
    "        src_lang=src_lang,\n",
    "        tgt_lang=\"eng_Latn\",\n",
    "    )\n",
    "    return translator\n",
    "\n",
    "def tokenize_question(df: pl.DataFrame, use_cache: bool = True, translation: bool = True, tokenization: bool = True) -> pl.DataFrame:\n",
    "    \n",
    "    # Check if already tokenized and translated\n",
    "    src_lang = lang_dict[df[\"lang\"][0]]\n",
    "    cache_path = os.path.join(\"data\", f\"tydi_xor_rc_{src_lang}\")\n",
    "    print(f\"Tokenizing and translating {src_lang}...\")\n",
    "    if use_cache and f\"tydi_xor_rc_{src_lang}.parquet\" in os.listdir(\"data\"):\n",
    "        # Load from parquet\n",
    "        print(f\"Loading from cached file tydi_xor_rc_{src_lang}.parquet\")\n",
    "\n",
    "        return pl.read_parquet(os.path.join(\"data\", f\"tydi_xor_rc_{src_lang}.parquet\"))\n",
    "\n",
    "    if tokenization:\n",
    "        # Tokenize questions using multilingual BERT tokenizer\n",
    "        print(\"Tokenizing\")\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"question\")\n",
    "            .map_elements(lambda x: nllb_tokenizer.tokenize(x), return_dtype=pl.List(pl.Utf8))\n",
    "            .alias(\"tokens\")\n",
    "        )\n",
    "\n",
    "    if translation:\n",
    "        print(\"Translating\")\n",
    "        # Translate questions using NLLB-200\n",
    "        translator = _make_translator(src_lang)\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"question\")\n",
    "            .map_elements(lambda x: translator(x)[0][\"translation_text\"])\n",
    "            .alias(\"translation\")\n",
    "        )\n",
    "\n",
    "    if use_cache:\n",
    "        print(f\"Caching to {cache_path}.parquet and {cache_path}.xlsx\")\n",
    "        df.write_parquet(cache_path + \".parquet\")\n",
    "        df.write_excel(cache_path + \".xlsx\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e811d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and translating arb_Arab...\n",
      "Loading from cached file tydi_xor_rc_arb_Arab.parquet\n",
      "Tokenizing and translating kor_Hang...\n",
      "Loading from cached file tydi_xor_rc_kor_Hang.parquet\n",
      "Tokenizing and translating tel_Telu...\n",
      "Loading from cached file tydi_xor_rc_tel_Telu.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_355, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>question</th><th>context</th><th>lang</th><th>answerable</th><th>answer_start</th><th>answer</th><th>answer_inlang</th><th>tokens</th><th>translation</th></tr><tr><td>str</td><td>str</td><td>str</td><td>bool</td><td>i64</td><td>str</td><td>str</td><td>list[str]</td><td>str</td></tr></thead><tbody><tr><td>&quot;ప్రపంచంలో&nbsp;&nbsp;మొట్టమొదటి దూర విద్…</td><td>&quot;Referred to as &quot;People&#x27;s Unive…</td><td>&quot;te&quot;</td><td>true</td><td>236</td><td>&quot;London&quot;</td><td>null</td><td>[&quot;▁ప్రపంచంలో&quot;, &quot;▁మొట్టమొదటి&quot;, … &quot;▁?&quot;]</td><td>&quot;The world&#x27;s first distance lea…</td></tr><tr><td>&quot;1959వ సంవత్సరంలో భారతదేశ ప్రధా…</td><td>&quot;Since 1947, there have been 14…</td><td>&quot;te&quot;</td><td>true</td><td>220</td><td>&quot;Jawaharlal Nehru&quot;</td><td>null</td><td>[&quot;▁1959&quot;, &quot;వ&quot;, … &quot;?&quot;]</td><td>&quot;Who was the Prime Minister of …</td></tr><tr><td>&quot;ఏ కాకతీయ రాజు కర్నూలు జిల్లాను…</td><td>&quot;Rani Rudrama Devi (died 1289 o…</td><td>&quot;te&quot;</td><td>true</td><td>194</td><td>&quot;Prataparudra&quot;</td><td>null</td><td>[&quot;▁ఏ&quot;, &quot;▁కా&quot;, … &quot;?&quot;]</td><td>&quot;Which Kakatiya king was the la…</td></tr><tr><td>&quot;మానవ హక్కులు ఎన్ని?&quot;</td><td>&quot;The Declaration consists of 30…</td><td>&quot;te&quot;</td><td>true</td><td>28</td><td>&quot;30&quot;</td><td>null</td><td>[&quot;▁మానవ&quot;, &quot;▁హక్కు&quot;, … &quot;?&quot;]</td><td>&quot;How many human rights do you h…</td></tr><tr><td>&quot;భారదేశంలో అత్యధిక జనాభా కలిగిన…</td><td>&quot;Uttar Pradesh (; IAST: &quot;Uttar …</td><td>&quot;te&quot;</td><td>true</td><td>0</td><td>&quot;Uttar Pradesh&quot;</td><td>null</td><td>[&quot;▁భార&quot;, &quot;దేశ&quot;, … &quot;?&quot;]</td><td>&quot;Which is the most populous sta…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;కోళ్లు ఎక్కువగా ఏ దేశంలో కనిపి…</td><td>&quot;Since time immemorial, man has…</td><td>&quot;te&quot;</td><td>false</td><td>-1</td><td>&quot;United States of America&quot;</td><td>&quot;అమెరికా సంయుక్త రాష్ట్రాలు&quot;</td><td>[&quot;▁కో&quot;, &quot;ళ్లు&quot;, … &quot;?&quot;]</td><td>&quot;In what country are chickens m…</td></tr><tr><td>&quot;క్షయ వ్యాధికి విరుగుడు ఏ దేశంల…</td><td>&quot;Vaccines against anthrax for u…</td><td>&quot;te&quot;</td><td>false</td><td>-1</td><td>&quot;France&quot;</td><td>&quot;ఫ్రాన్స్&quot;</td><td>[&quot;▁క్ష&quot;, &quot;య&quot;, … &quot;?&quot;]</td><td>&quot;In what country was the antido…</td></tr><tr><td>&quot;ఖురాన్ ఏ అరబ్బీ భాషలో ఎవరు రాస…</td><td>&quot;are broken Other Names of the …</td><td>&quot;te&quot;</td><td>false</td><td>-1</td><td>&quot;Prophet Muhammad&quot;</td><td>&quot;ముహమ్మద్ ప్రవక్త&quot;</td><td>[&quot;▁ఖ&quot;, &quot;ు&quot;, … &quot;?&quot;]</td><td>&quot;Who wrote the Qur&#x27;an in which …</td></tr><tr><td>&quot;టెక్సస్ రాష్ట్రంలోని అతిపెద్ద …</td><td>&quot;Austin is the capital of the U…</td><td>&quot;te&quot;</td><td>false</td><td>-1</td><td>&quot;JP Morgan Chase Tower&quot;</td><td>&quot;జేపీ మోర్గాన్ ఛేజ్ టవర్&quot;</td><td>[&quot;▁టెక్&quot;, &quot;స&quot;, … &quot;▁?&quot;]</td><td>&quot;What is the largest man-made s…</td></tr><tr><td>&quot;తమిళనాడులో రాష్ట్ర మొదటి ముఖ్య…</td><td>&quot;It became the &#x27;Dravidakajagam&#x27;…</td><td>&quot;te&quot;</td><td>false</td><td>-1</td><td>&quot;C. N. Annadurai&quot;</td><td>&quot;సి.ఎన్.అన్నాదురై&quot;</td><td>[&quot;▁త&quot;, &quot;మి&quot;, … &quot;?&quot;]</td><td>&quot;Who was the first Chief Minist…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_355, 9)\n",
       "┌────────────┬────────────┬──────┬────────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ question   ┆ context    ┆ lang ┆ answerable ┆ … ┆ answer     ┆ answer_in ┆ tokens    ┆ translati │\n",
       "│ ---        ┆ ---        ┆ ---  ┆ ---        ┆   ┆ ---        ┆ lang      ┆ ---       ┆ on        │\n",
       "│ str        ┆ str        ┆ str  ┆ bool       ┆   ┆ str        ┆ ---       ┆ list[str] ┆ ---       │\n",
       "│            ┆            ┆      ┆            ┆   ┆            ┆ str       ┆           ┆ str       │\n",
       "╞════════════╪════════════╪══════╪════════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ ప్రపంచంలో    ┆ Referred   ┆ te   ┆ true       ┆ … ┆ London     ┆ null      ┆ [\"▁ప్రపంచం ┆ The       │\n",
       "│ మొట్టమొదటి దూర ┆ to as      ┆      ┆            ┆   ┆            ┆           ┆ లో\", \"▁మొట్ట ┆ world's   │\n",
       "│ విద్…        ┆ \"People's  ┆      ┆            ┆   ┆            ┆           ┆ మొదటి\", …   ┆ first     │\n",
       "│            ┆ Unive…     ┆      ┆            ┆   ┆            ┆           ┆           ┆ distance  │\n",
       "│            ┆            ┆      ┆            ┆   ┆            ┆           ┆           ┆ lea…      │\n",
       "│ 1959వ      ┆ Since      ┆ te   ┆ true       ┆ … ┆ Jawaharlal ┆ null      ┆ [\"▁1959\", ┆ Who was   │\n",
       "│ సంవత్సరంలో   ┆ 1947,      ┆      ┆            ┆   ┆ Nehru      ┆           ┆ \"వ\", …    ┆ the Prime │\n",
       "│ భారతదేశ ప్రధా… ┆ there have ┆      ┆            ┆   ┆            ┆           ┆ \"?\"]      ┆ Minister  │\n",
       "│            ┆ been 14…   ┆      ┆            ┆   ┆            ┆           ┆           ┆ of …      │\n",
       "│ ఏ కాకతీయ రాజు ┆ Rani       ┆ te   ┆ true       ┆ … ┆ Prataparud ┆ null      ┆ [\"▁ఏ\",    ┆ Which     │\n",
       "│ కర్నూలు     ┆ Rudrama    ┆      ┆            ┆   ┆ ra         ┆           ┆ \"▁కా\", …   ┆ Kakatiya  │\n",
       "│ జిల్లాను…     ┆ Devi (died ┆      ┆            ┆   ┆            ┆           ┆ \"?\"]      ┆ king was  │\n",
       "│            ┆ 1289 o…    ┆      ┆            ┆   ┆            ┆           ┆           ┆ the la…   │\n",
       "│ మానవ హక్కులు ┆ The Declar ┆ te   ┆ true       ┆ … ┆ 30         ┆ null      ┆ [\"▁మానవ\",  ┆ How many  │\n",
       "│ ఎన్ని?       ┆ ation      ┆      ┆            ┆   ┆            ┆           ┆ \"▁హక్కు\",  ┆ human     │\n",
       "│            ┆ consists   ┆      ┆            ┆   ┆            ┆           ┆ … \"?\"]    ┆ rights do │\n",
       "│            ┆ of 30…     ┆      ┆            ┆   ┆            ┆           ┆           ┆ you h…    │\n",
       "│ భారదేశంలో     ┆ Uttar      ┆ te   ┆ true       ┆ … ┆ Uttar      ┆ null      ┆ [\"▁భార\",   ┆ Which is  │\n",
       "│ అత్యధిక జనాభా  ┆ Pradesh (; ┆      ┆            ┆   ┆ Pradesh    ┆           ┆ \"దేశ\", …   ┆ the most  │\n",
       "│ కలిగిన…      ┆ IAST:      ┆      ┆            ┆   ┆            ┆           ┆ \"?\"]      ┆ populous  │\n",
       "│            ┆ \"Uttar …   ┆      ┆            ┆   ┆            ┆           ┆           ┆ sta…      │\n",
       "│ …          ┆ …          ┆ …    ┆ …          ┆ … ┆ …          ┆ …         ┆ …         ┆ …         │\n",
       "│ కోళ్లు       ┆ Since time ┆ te   ┆ false      ┆ … ┆ United     ┆ అమెరికా      ┆ [\"▁కో\",    ┆ In what   │\n",
       "│ ఎక్కువగా ఏ   ┆ immemorial ┆      ┆            ┆   ┆ States of  ┆ సంయుక్త    ┆ \"ళ్లు\", …  ┆ country   │\n",
       "│ దేశంలో కనిపి…  ┆ , man has… ┆      ┆            ┆   ┆ America    ┆ రాష్ట్రాలు    ┆ \"?\"]      ┆ are       │\n",
       "│            ┆            ┆      ┆            ┆   ┆            ┆           ┆           ┆ chickens  │\n",
       "│            ┆            ┆      ┆            ┆   ┆            ┆           ┆           ┆ m…        │\n",
       "│ క్షయ వ్యాధికి   ┆ Vaccines   ┆ te   ┆ false      ┆ … ┆ France     ┆ ఫ్రాన్స్      ┆ [\"▁క్ష\",   ┆ In what   │\n",
       "│ విరుగుడు ఏ  ┆ against    ┆      ┆            ┆   ┆            ┆           ┆ \"య\", …    ┆ country   │\n",
       "│ దేశంల…      ┆ anthrax    ┆      ┆            ┆   ┆            ┆           ┆ \"?\"]      ┆ was the   │\n",
       "│            ┆ for u…     ┆      ┆            ┆   ┆            ┆           ┆           ┆ antido…   │\n",
       "│ ఖురాన్ ఏ     ┆ are broken ┆ te   ┆ false      ┆ … ┆ Prophet    ┆ ముహమ్మద్    ┆ [\"▁ఖ\",    ┆ Who wrote │\n",
       "│ అరబ్బీ భాషలో   ┆ Other      ┆      ┆            ┆   ┆ Muhammad   ┆ ప్రవక్త     ┆ \"ు\", …    ┆ the       │\n",
       "│ ఎవరు రాస…   ┆ Names of   ┆      ┆            ┆   ┆            ┆           ┆ \"?\"]      ┆ Qur'an in │\n",
       "│            ┆ the …      ┆      ┆            ┆   ┆            ┆           ┆           ┆ which …   │\n",
       "│ టెక్సస్       ┆ Austin is  ┆ te   ┆ false      ┆ … ┆ JP Morgan  ┆ జేపీ మోర్గాన్   ┆ [\"▁టెక్\",   ┆ What is   │\n",
       "│ రాష్ట్రంలోని    ┆ the        ┆      ┆            ┆   ┆ Chase      ┆ ఛేజ్ టవర్    ┆ \"స\", …    ┆ the       │\n",
       "│ అతిపెద్ద …    ┆ capital of ┆      ┆            ┆   ┆ Tower      ┆           ┆ \"▁?\"]     ┆ largest   │\n",
       "│            ┆ the U…     ┆      ┆            ┆   ┆            ┆           ┆           ┆ man-made  │\n",
       "│            ┆            ┆      ┆            ┆   ┆            ┆           ┆           ┆ s…        │\n",
       "│ తమిళనాడులో    ┆ It became  ┆ te   ┆ false      ┆ … ┆ C. N.      ┆ సి.ఎన్.అన్నా  ┆ [\"▁త\",    ┆ Who was   │\n",
       "│ రాష్ట్ర మొదటి   ┆ the 'Dravi ┆      ┆            ┆   ┆ Annadurai  ┆ దురై       ┆ \"మి\", …    ┆ the first │\n",
       "│ ముఖ్య…      ┆ dakajagam' ┆      ┆            ┆   ┆            ┆           ┆ \"?\"]      ┆ Chief     │\n",
       "│            ┆ …          ┆      ┆            ┆   ┆            ┆           ┆           ┆ Minist…   │\n",
       "└────────────┴────────────┴──────┴────────────┴───┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_question(df_ar)\n",
    "tokenize_question(df_ko)\n",
    "tokenize_question(df_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e7cc59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic dataset\n",
      "Tokenizing and translating arb_Arab...\n",
      "Tokenizing\n",
      "Number of questions: 2558 Number of tokens: 33733\n",
      "Korean dataset\n",
      "Tokenizing and translating kor_Hang...\n",
      "Tokenizing\n",
      "Number of questions: 2422 Number of tokens: 25829\n",
      "Telugu dataset\n",
      "Tokenizing and translating tel_Telu...\n",
      "Tokenizing\n",
      "Number of questions: 1355 Number of tokens: 18365\n",
      "Arabic validation dataset\n",
      "Tokenizing and translating arb_Arab...\n",
      "Tokenizing\n",
      "Number of questions: 415 Number of tokens: 5604\n",
      "Korean validation dataset\n",
      "Tokenizing and translating kor_Hang...\n",
      "Tokenizing\n",
      "Number of questions: 356 Number of tokens: 3775\n",
      "Telugu validation dataset\n",
      "Tokenizing and translating tel_Telu...\n",
      "Tokenizing\n",
      "Number of questions: 384 Number of tokens: 5020\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Get the number of questions and the number of total tokens in each language\n",
    "def df_metadata(df: pl.DataFrame) -> None:\n",
    "    n_questions = df.height\n",
    "    tokens_list = tokenize_question(df, use_cache = False, translation=False)[\"tokens\"].to_list()\n",
    "    n_tokens = sum([len(tokens) for tokens in tokens_list])\n",
    "    print(f\"Number of questions: {n_questions} Number of tokens: {n_tokens}\")\n",
    "\n",
    "print(\"Arabic dataset\")\n",
    "df_metadata(df_ar)\n",
    "print(\"Korean dataset\")\n",
    "df_metadata(df_ko)\n",
    "print(\"Telugu dataset\")\n",
    "df_metadata(df_te)\n",
    "print(\"Arabic validation dataset\")\n",
    "df_metadata(df_ar_val)\n",
    "print(\"Korean validation dataset\")\n",
    "df_metadata(df_ko_val)\n",
    "print(\"Telugu validation dataset\")\n",
    "df_metadata(df_te_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf6b9ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and translating arb_Arab...\n",
      "Loading from cached file tydi_xor_rc_arb_Arab.parquet\n",
      "[('؟', 1483), ('▁؟', 1057), ('ية', 656), ('▁في', 609), ('▁من', 593), ('▁متى', 535), ('ة', 477), ('▁ما', 450), ('▁هو', 355), ('▁ال', 334)]\n",
      "Tokenizing and translating kor_Hang...\n",
      "Loading from cached file tydi_xor_rc_kor_Hang.parquet\n",
      "[('?', 2420), ('인가', 610), ('▁무엇인가', 592), ('은', 586), ('▁가장', 529), ('▁언제', 432), ('의', 388), ('는가', 354), ('는', 323), ('▁몇', 320)]\n",
      "Tokenizing and translating tel_Telu...\n",
      "Loading from cached file tydi_xor_rc_tel_Telu.parquet\n",
      "[('?', 1093), ('▁ఎవరు', 274), ('▁?', 260), ('▁ఏ', 223), ('▁ఏది', 192), ('ంలో', 169), ('▁ఎన్ని', 165), ('▁జి', 163), ('మ', 157), ('▁ఎప్పుడు', 154)]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and translate each language dataframe, then compute token frequencies\n",
    "for df in [df_ar, df_ko, df_te]:\n",
    "    df = tokenize_question(df)\n",
    "    count_dict = {}\n",
    "    for tokens in df[\"tokens\"]:\n",
    "        for token in tokens:\n",
    "            if token in count_dict:\n",
    "                count_dict[token] += 1\n",
    "            else:\n",
    "                count_dict[token] = 1\n",
    "    sorted_frequency_list = sorted(count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(sorted_frequency_list[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6593567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and translating arb_Arab...\n",
      "Loading from cached file tydi_xor_rc_arb_Arab.parquet\n",
      "[('▁the', 2252), ('?', 1600), ('▁?', 984), ('▁of', 867), ('▁What', 687), ('s', 576), ('▁When', 567), ('▁in', 545), ('▁is', 539), ('▁was', 538)]\n",
      "Tokenizing and translating kor_Hang...\n",
      "Loading from cached file tydi_xor_rc_kor_Hang.parquet\n",
      "[('?', 2716), ('▁the', 2350), ('▁What', 929), ('▁is', 857), ('▁in', 844), ('▁of', 759), (\"'\", 646), ('s', 639), ('▁was', 446), ('▁When', 431)]\n",
      "Tokenizing and translating tel_Telu...\n",
      "Loading from cached file tydi_xor_rc_tel_Telu.parquet\n",
      "[('?', 1392), ('▁the', 1254), ('▁is', 682), ('▁of', 681), ('▁What', 459), ('▁in', 439), ('▁Who', 324), ('▁was', 283), ('▁How', 206), ('▁many', 181)]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and translate each language dataframe, then compute token frequencies of the translations\n",
    "for df in [df_ar, df_ko, df_te]:\n",
    "    df = tokenize_question(df)\n",
    "    count_dict = {}\n",
    "    for translation in df[\"translation\"]:\n",
    "        for token in nllb_tokenizer.tokenize(translation):\n",
    "            if token in count_dict:\n",
    "                count_dict[token] += 1\n",
    "            else:\n",
    "                count_dict[token] = 1\n",
    "    sorted_frequency_list = sorted(count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(sorted_frequency_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9743ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and translating arb_Arab...\n",
      "Loading from cached file tydi_xor_rc_arb_Arab.parquet\n",
      "Top tokens in arb_Arab answerable=True: [('▁the', 2090), ('?', 1446), ('▁?', 884), ('▁of', 806), ('▁What', 683), ('▁When', 567), ('s', 555), ('▁was', 537), ('▁is', 533), ('▁in', 477)]\n",
      "Top tokens in arb_Arab answerable=False: [('▁the', 162), ('?', 154), ('▁Is', 122), ('▁?', 100), ('▁a', 73), ('▁in', 68), ('▁of', 61), ('▁to', 44), ('▁Does', 29), ('▁Can', 27)]\n",
      "Tokenizing and translating kor_Hang...\n",
      "Loading from cached file tydi_xor_rc_kor_Hang.parquet\n",
      "Top tokens in kor_Hang answerable=True: [('?', 2654), ('▁the', 2299), ('▁What', 925), ('▁is', 849), ('▁in', 825), ('▁of', 733), (\"'\", 643), ('s', 635), ('▁was', 446), ('▁When', 430)]\n",
      "Top tokens in kor_Hang answerable=False: [('?', 62), ('▁the', 51), ('▁of', 26), ('▁in', 19), ('▁a', 18), ('▁Is', 16), ('▁Can', 9), ('▁Does', 8), ('▁is', 8), ('▁have', 8)]\n",
      "Tokenizing and translating tel_Telu...\n",
      "Loading from cached file tydi_xor_rc_tel_Telu.parquet\n",
      "Top tokens in tel_Telu answerable=True: [('?', 1347), ('▁the', 1212), ('▁is', 659), ('▁of', 653), ('▁What', 438), ('▁in', 422), ('▁Who', 317), ('▁was', 277), ('▁How', 203), ('▁many', 180)]\n",
      "Top tokens in tel_Telu answerable=False: [('?', 45), ('▁the', 42), ('▁of', 28), ('▁is', 23), ('▁What', 21), ('▁in', 17), ('▁country', 8), ('▁what', 8), ('▁Who', 7), ('▁first', 6)]\n"
     ]
    }
   ],
   "source": [
    "# Top tokens in answerable true and false\n",
    "for df in [df_ar, df_ko, df_te]:\n",
    "    df = tokenize_question(df)\n",
    "    for answerable in [True, False]:\n",
    "        count_dict = {}\n",
    "        for translation in df.filter(pl.col(\"answerable\") == answerable)[\"translation\"]:\n",
    "            for token in nllb_tokenizer.tokenize(translation):\n",
    "                if token in count_dict:\n",
    "                    count_dict[token] += 1\n",
    "                else:\n",
    "                    count_dict[token] = 1\n",
    "        sorted_frequency_list = sorted(count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"Top tokens in {lang_dict[df['lang'][0]]} answerable={answerable}: {sorted_frequency_list[:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
