{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d681fbb",
   "metadata": {},
   "source": [
    "## Weak 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f93c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    pipeline,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import polars as pl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e76ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get huggingface dataset\n",
    "dataset = load_dataset(\"coastalcph/tydi_xor_rc\")\n",
    "df_train = pl.from_pandas(dataset[\"train\"].to_pandas())\n",
    "df_test = pl.from_pandas(dataset[\"test\"].to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b192fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question',\n",
       " 'context',\n",
       " 'lang',\n",
       " 'answerable',\n",
       " 'answer_start',\n",
       " 'answer',\n",
       " 'answer_inlang']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88bb540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>question</th><th>context</th><th>lang</th><th>answerable</th><th>answer_start</th><th>answer</th><th>answer_inlang</th></tr><tr><td>str</td><td>str</td><td>str</td><td>bool</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;উইকিলিকস কত সালে সর্বপ্রথম ইন্…</td><td>&quot;WikiLeaks () is an internation…</td><td>&quot;bn&quot;</td><td>true</td><td>182</td><td>&quot;2006&quot;</td><td>null</td></tr><tr><td>&quot;দ্বিতীয় বিশ্বযুদ্ধে কোন দেশ প…</td><td>&quot;The war in Europe concluded wi…</td><td>&quot;bn&quot;</td><td>true</td><td>48</td><td>&quot;Germany&quot;</td><td>null</td></tr><tr><td>&quot;মার্কিন যুক্তরাষ্ট্রের সংবিধান…</td><td>&quot;Same-sex marriage in the Unite…</td><td>&quot;bn&quot;</td><td>false</td><td>-1</td><td>&quot;no&quot;</td><td>null</td></tr><tr><td>&quot;আরব-ইসরায়েলি যুদ্ধে আরবের মোট…</td><td>&quot;The exact number of Arab casua…</td><td>&quot;bn&quot;</td><td>true</td><td>39</td><td>&quot;unknown&quot;</td><td>null</td></tr><tr><td>&quot;বিশ্বে প্রথম পুঁজিবাদী সমাজ কব…</td><td>&quot;As Thomas Hall (2000) notes, &quot;…</td><td>&quot;bn&quot;</td><td>true</td><td>1219</td><td>&quot;17th century&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌────────────────┬───────────────┬──────┬────────────┬──────────────┬──────────────┬───────────────┐\n",
       "│ question       ┆ context       ┆ lang ┆ answerable ┆ answer_start ┆ answer       ┆ answer_inlang │\n",
       "│ ---            ┆ ---           ┆ ---  ┆ ---        ┆ ---          ┆ ---          ┆ ---           │\n",
       "│ str            ┆ str           ┆ str  ┆ bool       ┆ i64          ┆ str          ┆ str           │\n",
       "╞════════════════╪═══════════════╪══════╪════════════╪══════════════╪══════════════╪═══════════════╡\n",
       "│ উইকিলিকস কত    ┆ WikiLeaks ()  ┆ bn   ┆ true       ┆ 182          ┆ 2006         ┆ null          │\n",
       "│ সালে সর্বপ্রথম    ┆ is an         ┆      ┆            ┆              ┆              ┆               │\n",
       "│ ইন্…            ┆ internation…  ┆      ┆            ┆              ┆              ┆               │\n",
       "│ দ্বিতীয়         ┆ The war in    ┆ bn   ┆ true       ┆ 48           ┆ Germany      ┆ null          │\n",
       "│ বিশ্বযুদ্ধে কোন   ┆ Europe        ┆      ┆            ┆              ┆              ┆               │\n",
       "│ দেশ প…         ┆ concluded wi… ┆      ┆            ┆              ┆              ┆               │\n",
       "│ মার্কিন          ┆ Same-sex      ┆ bn   ┆ false      ┆ -1           ┆ no           ┆ null          │\n",
       "│ যুক্তরাষ্ট্রের      ┆ marriage in   ┆      ┆            ┆              ┆              ┆               │\n",
       "│ সংবিধান…        ┆ the Unite…    ┆      ┆            ┆              ┆              ┆               │\n",
       "│ আরব-ইসরায়েলি    ┆ The exact     ┆ bn   ┆ true       ┆ 39           ┆ unknown      ┆ null          │\n",
       "│ যুদ্ধে আরবের     ┆ number of     ┆      ┆            ┆              ┆              ┆               │\n",
       "│ মোট…           ┆ Arab casua…   ┆      ┆            ┆              ┆              ┆               │\n",
       "│ বিশ্বে প্রথম     ┆ As Thomas     ┆ bn   ┆ true       ┆ 1219         ┆ 17th century ┆ null          │\n",
       "│ পুঁজিবাদী সমাজ কব… ┆ Hall (2000)   ┆      ┆            ┆              ┆              ┆               │\n",
       "│                ┆ notes, \"…     ┆      ┆            ┆              ┆              ┆               │\n",
       "└────────────────┴───────────────┴──────┴────────────┴──────────────┴──────────────┴───────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5712570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = df_train.filter(pl.col(\"lang\") == \"ar\")\n",
    "df_ko = df_train.filter(pl.col(\"lang\") == \"ko\")\n",
    "df_te = df_train.filter(pl.col(\"lang\") == \"te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9920e3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>question</th><th>context</th><th>lang</th><th>answerable</th><th>answer_start</th><th>answer</th><th>answer_inlang</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;1355&quot;</td><td>&quot;1355&quot;</td><td>&quot;1355&quot;</td><td>1355.0</td><td>1355.0</td><td>&quot;1355&quot;</td><td>&quot;50&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>&quot;0&quot;</td><td>&quot;1305&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>null</td><td>0.96679</td><td>142.467159</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>191.558834</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;1950 నాటికి విశాఖపట్నం జిల్లాల…</td><td>&quot;\n",
       "Gerschenkron did not define e…</td><td>&quot;te&quot;</td><td>0.0</td><td>-1.0</td><td>&quot;&quot;Ai&#x27;n-e Akbari&quot;&quot;</td><td>&quot;(100 °సెం.)&quot;</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>17.0</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>79.0</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>198.0</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;హ్యారీ పోట్టర్ చిత్ర కథానాయకుడ…</td><td>&quot;will be the place. The nuclear…</td><td>&quot;te&quot;</td><td>1.0</td><td>2400.0</td><td>&quot;złoty&quot;</td><td>&quot;సి.ఎన్.అన్నాదురై&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 8)\n",
       "┌────────────┬──────────┬──────────────┬──────┬────────────┬──────────────┬─────────┬──────────────┐\n",
       "│ statistic  ┆ question ┆ context      ┆ lang ┆ answerable ┆ answer_start ┆ answer  ┆ answer_inlan │\n",
       "│ ---        ┆ ---      ┆ ---          ┆ ---  ┆ ---        ┆ ---          ┆ ---     ┆ g            │\n",
       "│ str        ┆ str      ┆ str          ┆ str  ┆ f64        ┆ f64          ┆ str     ┆ ---          │\n",
       "│            ┆          ┆              ┆      ┆            ┆              ┆         ┆ str          │\n",
       "╞════════════╪══════════╪══════════════╪══════╪════════════╪══════════════╪═════════╪══════════════╡\n",
       "│ count      ┆ 1355     ┆ 1355         ┆ 1355 ┆ 1355.0     ┆ 1355.0       ┆ 1355    ┆ 50           │\n",
       "│ null_count ┆ 0        ┆ 0            ┆ 0    ┆ 0.0        ┆ 0.0          ┆ 0       ┆ 1305         │\n",
       "│ mean       ┆ null     ┆ null         ┆ null ┆ 0.96679    ┆ 142.467159   ┆ null    ┆ null         │\n",
       "│ std        ┆ null     ┆ null         ┆ null ┆ null       ┆ 191.558834   ┆ null    ┆ null         │\n",
       "│ min        ┆ 1950 నాటికి ┆              ┆ te   ┆ 0.0        ┆ -1.0         ┆ \"Ai'n-e ┆ (100 °సెం.)   │\n",
       "│            ┆ విశాఖపట్నం  ┆ Gerschenkron ┆      ┆            ┆              ┆ Akbari\" ┆              │\n",
       "│            ┆ జిల్లాల…    ┆ did not      ┆      ┆            ┆              ┆         ┆              │\n",
       "│            ┆          ┆ define e…    ┆      ┆            ┆              ┆         ┆              │\n",
       "│ 25%        ┆ null     ┆ null         ┆ null ┆ null       ┆ 17.0         ┆ null    ┆ null         │\n",
       "│ 50%        ┆ null     ┆ null         ┆ null ┆ null       ┆ 79.0         ┆ null    ┆ null         │\n",
       "│ 75%        ┆ null     ┆ null         ┆ null ┆ null       ┆ 198.0        ┆ null    ┆ null         │\n",
       "│ max        ┆ హ్యారీ పోట్టర్ ┆ will be the  ┆ te   ┆ 1.0        ┆ 2400.0       ┆ złoty   ┆ సి.ఎన్.అన్నాదురై  │\n",
       "│            ┆ చిత్ర      ┆ place. The   ┆      ┆            ┆              ┆         ┆              │\n",
       "│            ┆ కథానాయకుడ… ┆ nuclear…     ┆      ┆            ┆              ┆         ┆              │\n",
       "└────────────┴──────────┴──────────────┴──────┴────────────┴──────────────┴─────────┴──────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ed480",
   "metadata": {},
   "source": [
    "### Get tokenizers and look at sample (Arabic) sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466187e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multilingual BERT tokenizer\n",
    "mbert_tokenizer = Tokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "# Load GPT-4 tokenizer\n",
    "gpt4_tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "# Load NLLB-200 tokenizer\n",
    "nllb_tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b133cb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] | م | ##تى | ت | ##دخل | ##ت | روسيا | في | الحرب | الا | ##هل | ##ية | السورية | ؟ | [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" | \".join(mbert_tokenizer.encode(df_ar[\"question\"][0]).tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23a80d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'م | ت | ى |  ت | د | خ | ل | ت |  ر | و | س | ي | ا |  في |   |  ال | ح | ر | ب |  ال | أ | ه | ل | ية |  ال | س | ور | ية | � | �'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode each token from GPT-4 tokenizer\n",
    "\" | \".join([gpt4_tokenizer.decode([token]) for token in gpt4_tokenizer.encode(df_ar[\"question\"][0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e331fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁متى | ▁تد | خ | لت | ▁روس | يا | ▁في | ▁الحرب | ▁الأ | ه | لية | ▁الس | ور | ية | ؟'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" | \".join(nllb_tokenizer.tokenize(df_ar[\"question\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955647f",
   "metadata": {},
   "source": [
    "## Get the top 5 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1168e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language dict\n",
    "lang_dict = {\n",
    "    \"ar\": \"arb_Arab\",\n",
    "    \"ko\": \"kor_Hang\",\n",
    "    \"te\": \"tel_Telu\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0adf1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up translation pipeline for NLLB-200\n",
    "translator_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a606491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Who is the winner of the Thirty Years' War?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_txt = df_ko[\"question\"][0]\n",
    "translator = translator = pipeline(\n",
    "        \"translation\",\n",
    "        model=translator_model,\n",
    "        tokenizer=nllb_tokenizer,\n",
    "        src_lang=\"kor_Hang\",\n",
    "        tgt_lang=\"eng_Latn\",\n",
    "    )\n",
    "translator(random_txt)[0][\"translation_text\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab4ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize questions in Arabic using multilingual BERT tokenizer\n",
    "def _make_translator(src_lang:str):\n",
    "    translator = pipeline(\n",
    "        \"translation\",\n",
    "        model=translator_model,\n",
    "        tokenizer=nllb_tokenizer,\n",
    "        src_lang=src_lang,\n",
    "        tgt_lang=\"eng_Latn\",\n",
    "    )\n",
    "    return translator\n",
    "\n",
    "def tokenize_question(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \n",
    "    src_lang = lang_dict[df[\"lang\"][0]]\n",
    "    print(f\"Tokenizing and translating {src_lang}...\")\n",
    "    print(f\"tydi_xor_rc_{src_lang}.parquet\" in os.listdir())\n",
    "    if f\"tydi_xor_rc_{src_lang}.parquet\" in os.listdir():\n",
    "        return pl.read_parquet(f\"tydi_xor_rc_{src_lang}.parquet\")\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"question\")\n",
    "        .map_elements(lambda x: nllb_tokenizer.tokenize(x), return_dtype=pl.List(pl.Utf8))\n",
    "        .alias(\"tokens\")\n",
    "    )\n",
    "\n",
    "    translator = _make_translator(src_lang)\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"question\")\n",
    "        .map_elements(lambda x: translator(x)[0][\"translation_text\"])\n",
    "        .alias(\"translation\")\n",
    "    )\n",
    "\n",
    "    df.write_parquet(f\"tydi_xor_rc_{src_lang}.parquet\")\n",
    "    df.write_excel(f\"tydi_xor_rc_{src_lang}.xlsx\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b9ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and translating arb_Arab...\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for df in [df_ar, df_ko, df_te]:\n",
    "    df = tokenize_question(df)\n",
    "    print(df.head())\n",
    "\n",
    "#df_ar = tokenize_question(df_ar)\n",
    "#df_ar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c926c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict_ar = {}\n",
    "for tokens in df_ar[\"tokens\"]:\n",
    "    for token in tokens:\n",
    "        if token in count_dict_ar:\n",
    "            count_dict_ar[token] += 1\n",
    "        else:\n",
    "            count_dict_ar[token] = 1\n",
    "# Get as tuple and sort by frequency\n",
    "sorted_frequency_list_ar = sorted(count_dict_ar.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_frequency_list_ar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
