{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf09889",
   "metadata": {},
   "source": [
    "# RuleBased Classification of QA dataset\n",
    "Load in libs, dataframe and examine answerable=true proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from data.const import ARB_CACHE, KOR_CACHE, TELU_CACHE\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = pl.read_parquet(ARB_CACHE)\n",
    "df_ko = pl.read_parquet(KOR_CACHE)\n",
    "df_te = pl.read_parquet(TELU_CACHE)\n",
    "df_arkote = pl.concat([df_ar, df_ko, df_te])\n",
    "assert df_ar.height + df_ko.height + df_te.height == df_arkote.height; # sanity check\n",
    "print(f\"Answerable proportion: {df_arkote['answerable'].sum() / df_arkote.height:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41157d3e",
   "metadata": {},
   "source": [
    "### Expression based approach to making rule based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_positive_rule() -> pl.Expr:\n",
    "    # Guessing positive in all cases as a baseline\n",
    "    return pl.lit(True)\n",
    "\n",
    "\n",
    "def when_rule() -> pl.Expr:\n",
    "    return pl.col(\"translation\").str.to_lowercase().str.contains(\"when\") & pl.col(\"context\").str.contains(r\"\\d\")\n",
    "\n",
    "def although_rule() -> pl.Expr:\n",
    "    return ~pl.col(\"context\").str.to_lowercase().str.contains(\"although\")\n",
    "\n",
    "def does_rule() -> pl.Expr:\n",
    "    return ~pl.col(\"translation\").str.to_lowercase().str.contains(\"does\")\n",
    "\n",
    "def first_letter_rule() -> pl.Expr:\n",
    "    return pl.col(\"translation\").str.slice(0, 1).str.to_lowercase().is_in([\"w\", \"h\"])\n",
    "\n",
    "def rule_based_classification() -> pl.Expr:\n",
    "    return (although_rule() & does_rule()) | (when_rule() | first_letter_rule())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eddb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_performance(df_ :pl.DataFrame):\n",
    "    # Proportion of answerable predictions\n",
    "    print(f\"Answerable proportion: {df_['answerable'].sum() / df_.height:.2f}\")\n",
    "    print(f\"Predicted answerable proportion: {df_['answerable_pred'].sum() / df_.height:.2f}\")\n",
    "\n",
    "    # Evaluate the rule-based classification\n",
    "    true_positives = df_.filter(pl.col(\"answerable\") & pl.col(\"answerable_pred\")).height \n",
    "    false_positives = df_.filter(~pl.col(\"answerable\") & pl.col(\"answerable_pred\")).height\n",
    "    true_negatives = df_.filter(~pl.col(\"answerable\") & ~pl.col(\"answerable_pred\")).height\n",
    "    false_negatives = df_.filter(pl.col(\"answerable\") & ~pl.col(\"answerable_pred\")).height\n",
    "    print(f\"True Positives: {true_positives} , False Positives: {false_positives}\")\n",
    "    print(f\"True Negatives: {true_negatives} , False Negatives: {false_negatives}\")\n",
    "\n",
    "    # Accuracy, Precision, Recall, F1 Score\n",
    "    accuracy = (true_positives + true_negatives) / df_.height\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score:.2f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    confusion_matrix = [[true_positives, false_negatives],\n",
    "                        [false_positives, true_negatives]]\n",
    "    plt.imshow(confusion_matrix)\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0, 1], ['P', 'N'])\n",
    "    plt.yticks([0, 1], ['P', 'N'])\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e96f8",
   "metadata": {},
   "source": [
    "### Performance of rules based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f98e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of each individual rule\n",
    "print(\"JUST POSITIVE RULE PERFORMANCE\")\n",
    "show_performance(df_arkote.with_columns(\n",
    "    just_positive_rule().alias(\"answerable_pred\")\n",
    "))\n",
    "print(\"ALTHOUGH RULE PERFORMANCE\")\n",
    "show_performance(df_arkote.with_columns(\n",
    "    although_rule().alias(\"answerable_pred\")\n",
    "))\n",
    "print(\"DOES RULE PERFORMANCE\")\n",
    "show_performance(df_arkote.with_columns(\n",
    "    does_rule().alias(\"answerable_pred\")\n",
    "))\n",
    "print(\"FIRST LETTER RULE PERFORMANCE\")\n",
    "show_performance(df_arkote.with_columns(\n",
    "    first_letter_rule().alias(\"answerable_pred\")\n",
    "))\n",
    "print(\"WHEN RULE PERFORMANCE\")\n",
    "show_performance(df_arkote.with_columns(\n",
    "    when_rule().alias(\"answerable_pred\")\n",
    "))\n",
    "print(\"COMBINED RULES PERFORMANCE\")\n",
    "show_performance(df_arkote.with_columns(\n",
    "    rule_based_classification().alias(\"answerable_pred\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Combined dataset performance\")\n",
    "show_performance(df_arkote.with_columns(\n",
    "    rule_based_classification().alias(\"answerable_pred\")\n",
    "))\n",
    "print(\"Arabic dataset performance\")\n",
    "show_performance(df_ar.with_columns(\n",
    "    rule_based_classification().alias(\"answerable_pred\")\n",
    "))\n",
    "print(\"Korean dataset performance\")\n",
    "show_performance(df_ko.with_columns(\n",
    "    rule_based_classification().alias(\"answerable_pred\")\n",
    "))\n",
    "print(\"Telugu dataset performance\")\n",
    "show_performance(df_te.with_columns(\n",
    "    rule_based_classification().alias(\"answerable_pred\")\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
